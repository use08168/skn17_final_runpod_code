{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d990f33d-370f-4062-810d-f5e2330e6041",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# Cell 0 : ì¶”ê°€ íŒ¨í‚¤ì§€ ì„¤ì¹˜\n",
    "# ==========================================\n",
    "\n",
    "# ì„¤ì¹˜ë¥¼ í–ˆëŠ”ë° ì…€ 3ë²ˆ 7ë²ˆì—ì„œ ì‘ë™ì´ ì•ˆ ë  ê²½ìš° í„°ë¯¸ë„ì—ì„œ skn17_final_env ì»¤ë„ì´ ì—°ê²°ë˜ì–´ ìˆëŠ” ìƒí™©ì—ì„œ ì„¤ì¹˜\n",
    "!pip install audio_separator\n",
    "!pip install -U bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4609630d-dfd6-4526-8d10-4ce34c1ccf0b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROJECT_ROOT: /workspace/baseball_pipeline\n",
      "\n",
      "âœ… ë””ë ‰í† ë¦¬ ìƒì„± ì™„ë£Œ\n",
      "âœ… API í† í° ì„¤ì • ì™„ë£Œ\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# Cell 1: ê²½ë¡œ ì„¤ì • ë° í† í° í™œì„±í™”\n",
    "# ==========================================\n",
    "\n",
    "from pathlib import Path\n",
    "import os, sys\n",
    "import json\n",
    "\n",
    "# ---- í”„ë¡œì íŠ¸ ë£¨íŠ¸ ----\n",
    "PROJECT_ROOT = Path(\"/workspace/baseball_pipeline\")\n",
    "os.chdir(PROJECT_ROOT)\n",
    "\n",
    "if str(PROJECT_ROOT) not in sys.path:\n",
    "    sys.path.append(str(PROJECT_ROOT))\n",
    "\n",
    "print(\"PROJECT_ROOT:\", PROJECT_ROOT)\n",
    "\n",
    "# ---- ë°ì´í„° ë””ë ‰í† ë¦¬ ----\n",
    "from src import DATA_DIR, FAISS_DIR, FISH_ROOT\n",
    "\n",
    "INPUT_VIDEO_DIR = DATA_DIR / \"input_videos\"\n",
    "STT_RAW_DIR = DATA_DIR / \"stt_raw\"\n",
    "STT_SEG_DIR = DATA_DIR / \"stt_segments\"\n",
    "LLM_OUT_DIR = DATA_DIR / \"llm_outputs\"\n",
    "TTS_AUDIO_DIR = DATA_DIR / \"tts_audio\"\n",
    "OUTPUT_VIDEO_DIR = DATA_DIR / \"output_videos\"\n",
    "AUDIO_ROOT = DATA_DIR / \"audio_separator\"\n",
    "FRAMES_ROOT = DATA_DIR / \"frames\"\n",
    "SRC_ROOT = PROJECT_ROOT / \"src\"\n",
    "\n",
    "if str(SRC_ROOT) not in sys.path:\n",
    "    sys.path.append(str(SRC_ROOT))\n",
    "\n",
    "# ë””ë ‰í† ë¦¬ ìƒì„±\n",
    "for d in (DATA_DIR, INPUT_VIDEO_DIR, STT_RAW_DIR, STT_SEG_DIR, \n",
    "          LLM_OUT_DIR, TTS_AUDIO_DIR, OUTPUT_VIDEO_DIR, AUDIO_ROOT, \n",
    "          FRAMES_ROOT, FAISS_DIR, SRC_ROOT):\n",
    "    d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"\\nâœ… ë””ë ‰í† ë¦¬ ìƒì„± ì™„ë£Œ\")\n",
    "\n",
    "# ---- API í† í° ì„¤ì • ----\n",
    "CLOVA_INVOKE_URL = \"\"\n",
    "CLOVA_SECRET_KEY = \"\"\n",
    "\n",
    "HF_TOKEN = \"\"\n",
    "# OPENAI_API_KEY = \"sk-proj-...\"  # í•„ìš”ì‹œ ì…ë ¥\n",
    "\n",
    "if HF_TOKEN and \"xxx\" not in HF_TOKEN:\n",
    "    os.environ[\"HF_TOKEN\"] = HF_TOKEN\n",
    "    os.environ[\"HUGGINGFACE_HUB_TOKEN\"] = HF_TOKEN\n",
    "    os.environ[\"HUGGING_FACE_HUB_TOKEN\"] = HF_TOKEN\n",
    "\n",
    "# if OPENAI_API_KEY:\n",
    "#     os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY\n",
    "\n",
    "print(\"âœ… API í† í° ì„¤ì • ì™„ë£Œ\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad4643c8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GDRIVE] file_id: 1kqN0IAerBH72RnoQwXzM-T-rrwoaMLDn\n",
      "[GDRIVE] url    : https://drive.google.com/uc?id=1kqN0IAerBH72RnoQwXzM-T-rrwoaMLDn\n",
      "[GDRIVE] output : /workspace/skn17_final_runpod_code/baseball_pipeline/data/input_videos/ì²´ì½”_ëŒ€í•œë¯¼êµ­_wbc.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=1kqN0IAerBH72RnoQwXzM-T-rrwoaMLDn\n",
      "From (redirected): https://drive.google.com/uc?id=1kqN0IAerBH72RnoQwXzM-T-rrwoaMLDn&confirm=t&uuid=69f2a8f3-c11d-49e4-b630-cc7d149a2e9b\n",
      "To: /workspace/skn17_final_runpod_code/baseball_pipeline/data/input_videos/ì²´ì½”_ëŒ€í•œë¯¼êµ­_wbc.mp4\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.29G/1.29G [00:25<00:00, 50.1MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GDRIVE] ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: /workspace/skn17_final_runpod_code/baseball_pipeline/data/input_videos/ì²´ì½”_ëŒ€í•œë¯¼êµ­_wbc.mp4\n",
      "\n",
      "âœ… ì˜ìƒ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ\n",
      "  video_stem: ì²´ì½”_ëŒ€í•œë¯¼êµ­_wbc\n",
      "  ê²½ë¡œ: /workspace/skn17_final_runpod_code/baseball_pipeline/data/input_videos/ì²´ì½”_ëŒ€í•œë¯¼êµ­_wbc.mp4\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from src.google_mp4_download import download_gdrive_video\n",
    "\n",
    "# ====== ì—¬ê¸°ì— êµ¬ê¸€ ë“œë¼ì´ë¸Œ ë§í¬ ì…ë ¥ ======\n",
    "gdrive_url = \"https://drive.google.com/file/d/1kqN0IAerBH72RnoQwXzM-T-rrwoaMLDn/view?usp=sharing\"\n",
    "VIDEO_NAME = \"ì²´ì½”_ëŒ€í•œë¯¼êµ­_wbc.mp4\"\n",
    "\n",
    "local_video_path = download_gdrive_video(gdrive_url, dest_name=VIDEO_NAME)\n",
    "video_stem = Path(VIDEO_NAME).stem\n",
    "\n",
    "print(f\"\\nâœ… ì˜ìƒ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ\")\n",
    "print(f\"  video_stem: {video_stem}\")\n",
    "print(f\"  ê²½ë¡œ: {local_video_path}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ce813e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# Cell 3: audio_separator ìŒì„± ë¶„ë¦¬\n",
    "# ==========================================\n",
    "from src.audio_separator import separate_audio_sota\n",
    "\n",
    "track_dict = separate_audio_sota(\n",
    "    video_path=str(local_video_path),\n",
    "    output_dir=str(AUDIO_ROOT),\n",
    "    device=\"cuda\"\n",
    ")\n",
    "\n",
    "vocals_path = track_dict[\"vocals\"]\n",
    "no_vocals_path = track_dict[\"no_vocals\"]\n",
    "\n",
    "print(f\"\\nâœ… ìŒì„± ë¶„ë¦¬ ì™„ë£Œ! (SOTA Performance)\")\n",
    "print(f\"  - í•´ì„¤(Vocals)    : {vocals_path}\")\n",
    "print(f\"  - í˜„ì¥ìŒ(No Vocals): {no_vocals_path}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a63c9a0-e8a4-477a-a306-69b70ec20b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# Cell 4: STT (Clova Speech API)\n",
    "# ==========================================\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "from src.stt_pipeline import run_stt_pipeline\n",
    "from src.stt_event_splitter import stt_json_to_event_sets\n",
    "\n",
    "print(f\"[STT] Clova STT ì‹œì‘\")\n",
    "print(f\"  ì…ë ¥: {vocals_path}\")\n",
    "\n",
    "STT_KEYWORD_XLSX = PROJECT_ROOT / \"stt.xlsx\"\n",
    "if STT_KEYWORD_XLSX.exists():\n",
    "    xlsx_path = STT_KEYWORD_XLSX\n",
    "    use_domain = False\n",
    "    print(\"  í‚¤ì›Œë“œ: stt.xlsx ì‚¬ìš© (ì—‘ì…€ ë¶€ìŠ¤íŒ…)\")\n",
    "else:\n",
    "    xlsx_path = None\n",
    "    use_domain = True\n",
    "    print(\"  í‚¤ì›Œë“œ: ë„ë©”ì¸ ë¶€ìŠ¤íŒ…ë§Œ ì‚¬ìš©\")\n",
    "\n",
    "# ---- STT íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ----\n",
    "timeline_json_path = run_stt_pipeline(\n",
    "    audio_path=vocals_path,\n",
    "    invoke_url=CLOVA_INVOKE_URL,\n",
    "    secret_key=CLOVA_SECRET_KEY,\n",
    "    stt_raw_dir=STT_RAW_DIR,\n",
    "    stt_seg_dir=STT_SEG_DIR,\n",
    "    xlsx_keywords_path=xlsx_path,\n",
    "    use_domain_boostings=use_domain,\n",
    "    speaker_count_min=2,\n",
    "    speaker_count_max=3,\n",
    "    save_raw_json=True,\n",
    "    pause_thresh_ms=50000,  # í•„ìš”ì‹œ ì¡°ì ˆ\n",
    ")\n",
    "\n",
    "print(f\"\\nâœ… STT ì™„ë£Œ!\")\n",
    "print(f\"timeline.json : {timeline_json_path}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4901fa9b-4f60-4f09-a783-8c0764eed938",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# Cell 5: STT ë°ì´í„° ì „ì²˜ë¦¬ (ì´ë²¤íŠ¸ ì„¸íŠ¸)\n",
    "# ==========================================\n",
    "from src.stt_event_splitter import stt_json_to_event_sets\n",
    "\n",
    "timeline_json_stem = timeline_json_path.stem\n",
    "# ê°™ì€ ë””ë ‰í„°ë¦¬ì— *_output.json ìœ¼ë¡œ ì €ì¥\n",
    "json_after_split_path = timeline_json_path.with_name(f\"{timeline_json_stem}_set_split.json\")\n",
    "\n",
    "# ì…ë ¥ JSON ë¡œë“œ\n",
    "with timeline_json_path.open(\"r\", encoding=\"utf-8\") as f:\n",
    "    stt_json = json.load(f)\n",
    "\n",
    "# ì´ë²¤íŠ¸ ì„¸íŠ¸ ë³€í™˜\n",
    "event_sets = stt_json_to_event_sets(\n",
    "    stt_json,\n",
    "    caster_gap=10.0,   # í•„ìš”ì‹œ íŠœë‹\n",
    "    silence_gap=2.0,  # í•„ìš”ì‹œ íŠœë‹\n",
    ")\n",
    "\n",
    "print(f\"ì´ë²¤íŠ¸ ì„¸íŠ¸ ê°œìˆ˜: {len(event_sets)}\")\n",
    "\n",
    "# ì¶œë ¥ JSON ì €ì¥\n",
    "with json_after_split_path.open(\"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(event_sets, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"ì €ì¥ ì™„ë£Œ: {json_after_split_path.resolve()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e28a5f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# Cell 6: ì˜ìƒ ì´ë¯¸ì§€ ì¶”ì¶œ\n",
    "# ==========================================\n",
    "\n",
    "import json\n",
    "\n",
    "from src.image_extraction import capture_frames_for_sets\n",
    "\n",
    "# ì„¸íŠ¸ json ë¡œë“œ\n",
    "with json_after_split_path.open(\"r\", encoding=\"utf-8\") as f:\n",
    "    sets = json.load(f)   # ë¦¬ìŠ¤íŠ¸ í˜•íƒœì—¬ì•¼ í•¨\n",
    "\n",
    "print(f\"ì„¸íŠ¸ ê°œìˆ˜: {len(sets)}\")\n",
    "\n",
    "# 5) ì„¸íŠ¸ì˜ set_start_sec ê¸°ì¤€ìœ¼ë¡œ ì´ë¯¸ì§€ ì¶”ì¶œ\n",
    "results = capture_frames_for_sets(\n",
    "    video_path=local_video_path,\n",
    "    sets=sets,\n",
    "    output_dir=FRAMES_ROOT\n",
    ")\n",
    "\n",
    "# 6) ìš”ì•½ ì¶œë ¥\n",
    "success_count = sum(1 for r in results if r[\"success\"])\n",
    "print(f\"ì„±ê³µì ìœ¼ë¡œ ì €ì¥ëœ ì´ë¯¸ì§€ ìˆ˜: {success_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da221745-5dd7-4ca0-8b3b-5dc889a719cb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# Cell 7: VLM ìŠ¤ì½”ì–´ë³´ë“œ ì¶”ì¶œ (ìµœì í™” ë²„ì „)\n",
    "# ==========================================\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from src.vlm_scoreboard import (\n",
    "    load_scoreboard_model_and_processor,\n",
    "    attach_scoreboard_to_sets,\n",
    ")\n",
    "\n",
    "# ==========================\n",
    "# ëª¨ë¸ / í”„ë¡œì„¸ì„œ ë¡œë“œ\n",
    "# ==========================\n",
    "\n",
    "vlm_model, vlm_processor = load_scoreboard_model_and_processor()\n",
    "\n",
    "\n",
    "# ==========================\n",
    "# scoreboard íŒŒì´í”„ë¼ì¸ ì‹¤í–‰\n",
    "# ==========================\n",
    "json_after_split_stem = json_after_split_path.stem\n",
    "# ê°™ì€ ë””ë ‰í„°ë¦¬ì— *_output.json ìœ¼ë¡œ ì €ì¥\n",
    "scoreboard_json_path = json_after_split_path.with_name(f\"{json_after_split_stem}_scoreboard.json\")\n",
    "\n",
    "updated_sets = attach_scoreboard_to_sets(\n",
    "    json_after_split_path=json_after_split_path,\n",
    "    output_json_path=scoreboard_json_path,\n",
    "    frames_root=FRAMES_ROOT,\n",
    "    video_path=local_video_path,\n",
    "    model=vlm_model,\n",
    "    processor=vlm_processor,\n",
    "    retry_if_all_null=False,   # all-nullì´ë©´ +2ì´ˆ ì¬ì‹œë„\n",
    "    retry_offset_sec=2.0,\n",
    ")\n",
    "\n",
    "print(f\"ì´ ì„¸íŠ¸ ìˆ˜: {len(updated_sets)}\")\n",
    "print(f\"ì €ì¥ ì™„ë£Œ: {scoreboard_json_path.resolve()}\")\n",
    "\n",
    "# ì¼ë¶€ë§Œ ëˆˆìœ¼ë¡œ í™•ì¸\n",
    "for s in updated_sets[:5]:\n",
    "    print(\"=\" * 80)\n",
    "    print(\"set_id:\", s[\"set_id\"])\n",
    "    print(\"set_start_sec:\", s[\"set_start_sec\"])\n",
    "    print(\"scoreboard:\", s[\"scoreboard\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f579767-1d19-414c-84e6-3e6cc243223c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "# from pakchanho_commentary_generator import (\n",
    "#     load_pakchanho_model,\n",
    "#     generate_analyst_for_all_sets,\n",
    "# )\n",
    "\n",
    "from src.llm_generator import (\n",
    "    load_pakchanho_model,\n",
    "    generate_analyst_for_all_sets,\n",
    ")\n",
    "\n",
    "# Pakchanho LLM ì ìš© í›„ ì €ì¥í•  ê²½ë¡œ\n",
    "json_llm_output_path = LLM_OUT_DIR / \"vocals_timeline_set_split_scoreboard_pakchanho.json\"\n",
    "\n",
    "# 1) ëª¨ë¸ ë¡œë“œ\n",
    "model, tokenizer = load_pakchanho_model(\n",
    "    base_model_name=\"kakaocorp/kanana-1.5-8b-instruct-2505\",\n",
    "    lora_model_id=\"SeHee8546/kanana-1.5-8b-pakchanho-lora-v2\",\n",
    "    load_in_4bit=True,\n",
    ")\n",
    "\n",
    "# 2) ì„¸íŠ¸ë³„ analyst_text ì¬ìƒì„±\n",
    "game_title = \"2025 KBO ì¤€í”Œë ˆì´ì˜¤í”„ 4ì°¨ì „ ì‚¼ì„± vs SSG\"  # ê²½ê¸° ì •ë³´ëŠ” ìƒí™©ì— ë§ê²Œ ë°”ê¾¸ë©´ ë¨\n",
    "\n",
    "result_sets = generate_analyst_for_all_sets(\n",
    "    json_in_path=scoreboard_json_path,\n",
    "    json_out_path=json_llm_output_path,\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    game_title=game_title,\n",
    "    temperature=0.7,\n",
    "    top_p=0.9,\n",
    "    repetition_penalty=1.1,\n",
    "    no_repeat_ngram_size=3,\n",
    "    base_max_new_tokens=512,\n",
    ")\n",
    "\n",
    "print(f\"ì´ ì„¸íŠ¸ ìˆ˜: {len(result_sets)}\")\n",
    "print(f\"ì €ì¥ ì™„ë£Œ: {json_llm_output_path.resolve()}\")\n",
    "\n",
    "# 3) ìƒ˜í”Œ ëª‡ ê°œ í™•ì¸\n",
    "for row in result_sets[:5]:\n",
    "    print(\"=\" * 80)\n",
    "    print(\"set_id:\", row[\"set_id\"])\n",
    "    print(\"caster_text:\", row[\"caster_text\"])\n",
    "    print(\"analyst_text:\", row[\"analyst_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "518f027d-028e-4e37-bbc1-be2095a9dfc2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# JSON ê¸°ë°˜ TTS ì „ì²´ íŒŒì´í”„ë¼ì¸ (ë¡œì»¬/RunPod í˜¸í™˜)\n",
    "# ==========================================\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from src.json_tts_pipeline import run_full_tts_pipeline_from_json\n",
    "\n",
    "\n",
    "# ========================================\n",
    "# í™˜ê²½ ìë™ ê°ì§€ ë° ê²½ë¡œ ì„¤ì •\n",
    "# ========================================\n",
    "\n",
    "def get_project_root() -> Path:\n",
    "    \"\"\"\n",
    "    í”„ë¡œì íŠ¸ ë£¨íŠ¸ ë””ë ‰í† ë¦¬ë¥¼ ìë™ìœ¼ë¡œ ì°¾ìŠµë‹ˆë‹¤.\n",
    "    - RunPod: /workspace/skn17_final_runpod_code\n",
    "    - ë¡œì»¬: í˜„ì¬ ë…¸íŠ¸ë¶ì´ ìˆëŠ” ìœ„ì¹˜ ê¸°ì¤€ìœ¼ë¡œ íƒìƒ‰\n",
    "    \"\"\"\n",
    "    # í˜„ì¬ ë…¸íŠ¸ë¶ íŒŒì¼ì˜ ë””ë ‰í† ë¦¬\n",
    "    current_dir = Path.cwd()\n",
    "    \n",
    "    # RunPod í™˜ê²½ ì²´í¬\n",
    "    runpod_path = Path(\"/workspace/skn17_final_runpod_code\")\n",
    "    if runpod_path.exists():\n",
    "        print(f\"ğŸ” í™˜ê²½ ê°ì§€: RunPod\")\n",
    "        return runpod_path\n",
    "    \n",
    "    # ë¡œì»¬ í™˜ê²½: ìƒìœ„ ë””ë ‰í† ë¦¬ë¥¼ íƒìƒ‰í•˜ë©° baseball_pipeline ë˜ëŠ” data í´ë” ì°¾ê¸°\n",
    "    for parent in [current_dir] + list(current_dir.parents):\n",
    "        # baseball_pipeline í´ë”ê°€ ìˆëŠ”ì§€ í™•ì¸\n",
    "        if (parent / \"baseball_pipeline\").exists():\n",
    "            print(f\"ğŸ” í™˜ê²½ ê°ì§€: ë¡œì»¬ (baseball_pipeline ë°œê²¬)\")\n",
    "            return parent\n",
    "        # data í´ë”ê°€ ìˆëŠ”ì§€ í™•ì¸\n",
    "        if (parent / \"data\").exists():\n",
    "            print(f\"ğŸ” í™˜ê²½ ê°ì§€: ë¡œì»¬ (data ë°œê²¬)\")\n",
    "            return parent\n",
    "    \n",
    "    # ì°¾ì§€ ëª»í–ˆìœ¼ë©´ í˜„ì¬ ë””ë ‰í† ë¦¬ ë°˜í™˜\n",
    "    print(f\"ğŸ” í™˜ê²½ ê°ì§€: í˜„ì¬ ë””ë ‰í† ë¦¬ ì‚¬ìš©\")\n",
    "    return current_dir\n",
    "\n",
    "# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ìë™ ê°ì§€\n",
    "PROJECT_ROOT = get_project_root()\n",
    "print(f\"ğŸ“ í”„ë¡œì íŠ¸ ë£¨íŠ¸: {PROJECT_ROOT}\\n\")\n",
    "\n",
    "# DATA_DIR ì„¤ì • (baseball_pipeline/data ë˜ëŠ” data)\n",
    "if (PROJECT_ROOT / \"baseball_pipeline\" / \"data\").exists():\n",
    "    DATA_DIR = PROJECT_ROOT / \"baseball_pipeline\" / \"data\"\n",
    "elif (PROJECT_ROOT / \"data\").exists():\n",
    "    DATA_DIR = PROJECT_ROOT / \"data\"\n",
    "else:\n",
    "    # ì—†ìœ¼ë©´ ìƒì„±\n",
    "    DATA_DIR = PROJECT_ROOT / \"data\"\n",
    "    DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "    print(f\"âš ï¸ data í´ë”ë¥¼ ìƒì„±í–ˆìŠµë‹ˆë‹¤: {DATA_DIR}\")\n",
    "\n",
    "print(f\"ğŸ“ ë°ì´í„° ë””ë ‰í† ë¦¬: {DATA_DIR}\\n\")\n",
    "\n",
    "\n",
    "# ========================================\n",
    "# ğŸ™ï¸ í•´ì„¤ìœ„ì› ì„ íƒ (1, 2, 3 ì¤‘ ì„ íƒ)\n",
    "# ========================================\n",
    "ANALYST_SELECT = 1  # 1: ë°•ì°¬í˜¸, 2: ì´ëŒ€í˜¸, 3: ê¹€ê´‘í˜„\n",
    "\n",
    "# í•´ì„¤ìœ„ì› ë§¤í•‘\n",
    "ANALYST_MAPPING = {\n",
    "    1: \"park\",   # ë°•ì°¬í˜¸\n",
    "    2: \"lee\",    # ì´ëŒ€í˜¸\n",
    "    3: \"kim\",    # ê¹€ê´‘í˜„\n",
    "}\n",
    "\n",
    "ANALYST_NAMES = {\n",
    "    1: \"ë°•ì°¬í˜¸\",\n",
    "    2: \"ì´ëŒ€í˜¸\",\n",
    "    3: \"ê¹€ê´‘í˜„\",\n",
    "}\n",
    "\n",
    "if ANALYST_SELECT not in ANALYST_MAPPING:\n",
    "    raise ValueError(f\"âŒ ANALYST_SELECTëŠ” 1, 2, 3 ì¤‘ í•˜ë‚˜ì—¬ì•¼ í•©ë‹ˆë‹¤. (í˜„ì¬: {ANALYST_SELECT})\")\n",
    "\n",
    "selected_analyst = ANALYST_MAPPING[ANALYST_SELECT]\n",
    "selected_analyst_name = ANALYST_NAMES[ANALYST_SELECT]\n",
    "print(f\"ğŸ™ï¸ ì„ íƒëœ í•´ì„¤ìœ„ì›: {selected_analyst_name} ({selected_analyst}) [ë²ˆí˜¸: {ANALYST_SELECT}]\\n\")\n",
    "\n",
    "# ========================================\n",
    "# íŒŒì¼ ê²½ë¡œ ì„¤ì •\n",
    "# ========================================\n",
    "\n",
    "# ì…ë ¥ íŒŒì¼ë“¤ (ë¡œì»¬/RunPodì— ë§ê²Œ ì„¤ì •)\n",
    "# ë¡œì»¬ì—ì„œëŠ” ì´ ë³€ìˆ˜ë“¤ì„ ë¨¼ì € ì •ì˜í•´ì•¼ í•©ë‹ˆë‹¤\n",
    "if 'local_video_path' not in locals():\n",
    "    # ì˜ˆì‹œ: ë¡œì»¬ì—ì„œ ì§ì ‘ ê²½ë¡œ ì§€ì •\n",
    "    local_video_path = DATA_DIR / \"input_videos\" / \"your_video.mp4\"\n",
    "    print(f\"âš ï¸ local_video_pathê°€ ì •ì˜ë˜ì§€ ì•Šì•„ ê¸°ë³¸ê°’ ì‚¬ìš©: {local_video_path}\")\n",
    "\n",
    "if 'json_llm_output_path' not in locals():\n",
    "    # ì˜ˆì‹œ: ë¡œì»¬ì—ì„œ ì§ì ‘ ê²½ë¡œ ì§€ì •\n",
    "    json_llm_output_path = DATA_DIR / \"llm_outputs\" / \"your_json.json\"\n",
    "    print(f\"âš ï¸ json_llm_output_pathê°€ ì •ì˜ë˜ì§€ ì•Šì•„ ê¸°ë³¸ê°’ ì‚¬ìš©: {json_llm_output_path}\")\n",
    "\n",
    "video_stem = Path(local_video_path).stem\n",
    "\n",
    "# Fish-Speech API ì„¤ì •\n",
    "FISH_API_URL = \"http://127.0.0.1:8080/v1/tts\"\n",
    "\n",
    "# ìºìŠ¤í„°ëŠ” ê³ ì •\n",
    "CASTER_REF_WAVS = [DATA_DIR / \"tts_refs\" / \"caster_jung.wav\"]\n",
    "\n",
    "# í•´ì„¤ìœ„ì›ì€ ì„ íƒì— ë”°ë¼ ë™ì ìœ¼ë¡œ ì„¤ì •\n",
    "ANALYST_REF_WAVS = [DATA_DIR / \"tts_refs\" / f\"analyst_{selected_analyst}.wav\"]\n",
    "\n",
    "# ========================================\n",
    "# íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸\n",
    "# ========================================\n",
    "print(\"=\" * 80)\n",
    "print(\"ğŸ“ ì°¸ì¡° ìŒì„± íŒŒì¼ í™•ì¸\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "all_refs_exist = True\n",
    "\n",
    "# ìºìŠ¤í„° ì°¸ì¡° í™•ì¸\n",
    "for ref_path in CASTER_REF_WAVS:\n",
    "    if ref_path.exists():\n",
    "        size_mb = ref_path.stat().st_size / (1024**2)\n",
    "        print(f\"âœ… ìºìŠ¤í„° ì°¸ì¡°: {ref_path.name} ({size_mb:.2f} MB)\")\n",
    "    else:\n",
    "        print(f\"âŒ ìºìŠ¤í„° ì°¸ì¡° ì—†ìŒ: {ref_path}\")\n",
    "        all_refs_exist = False\n",
    "\n",
    "# í•´ì„¤ìœ„ì› ì°¸ì¡° í™•ì¸\n",
    "for ref_path in ANALYST_REF_WAVS:\n",
    "    if ref_path.exists():\n",
    "        size_mb = ref_path.stat().st_size / (1024**2)\n",
    "        print(f\"âœ… í•´ì„¤ìœ„ì› ì°¸ì¡° ({selected_analyst_name}): {ref_path.name} ({size_mb:.2f} MB)\")\n",
    "    else:\n",
    "        print(f\"âŒ í•´ì„¤ìœ„ì› ì°¸ì¡° ì—†ìŒ: {ref_path}\")\n",
    "        all_refs_exist = False\n",
    "\n",
    "print(\"=\" * 80 + \"\\n\")\n",
    "\n",
    "if not all_refs_exist:\n",
    "    print(\"âŒ í•„ìš”í•œ ì°¸ì¡° ìŒì„± íŒŒì¼ ê²½ë¡œ:\")\n",
    "    print(f\"   {DATA_DIR / 'tts_refs'}\")\n",
    "    print(\"\\ní•„ìš”í•œ íŒŒì¼:\")\n",
    "    print(\"   - caster_jung.wav\")\n",
    "    print(\"   - analyst_park.wav (ë°•ì°¬í˜¸)\")\n",
    "    print(\"   - analyst_lee.wav (ì´ëŒ€í˜¸)\")\n",
    "    print(\"   - analyst_kim.wav (ê¹€ê´‘í˜„)\")\n",
    "    raise FileNotFoundError(\"âŒ í•„ìš”í•œ ì°¸ì¡° ìŒì„± íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤!\")\n",
    "\n",
    "# ì…ë ¥ íŒŒì¼ í™•ì¸\n",
    "print(\"=\" * 80)\n",
    "print(\"ğŸ“ ì…ë ¥ íŒŒì¼ í™•ì¸\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "if Path(local_video_path).exists():\n",
    "    size_mb = Path(local_video_path).stat().st_size / (1024**2)\n",
    "    print(f\"âœ… ì›ë³¸ ë¹„ë””ì˜¤: {Path(local_video_path).name} ({size_mb:.2f} MB)\")\n",
    "else:\n",
    "    print(f\"âŒ ì›ë³¸ ë¹„ë””ì˜¤ ì—†ìŒ: {local_video_path}\")\n",
    "    raise FileNotFoundError(f\"ì›ë³¸ ë¹„ë””ì˜¤ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {local_video_path}\")\n",
    "\n",
    "if Path(json_llm_output_path).exists():\n",
    "    size_kb = Path(json_llm_output_path).stat().st_size / 1024\n",
    "    print(f\"âœ… JSON ì„¸íŠ¸: {Path(json_llm_output_path).name} ({size_kb:.2f} KB)\")\n",
    "else:\n",
    "    print(f\"âŒ JSON ì„¸íŠ¸ ì—†ìŒ: {json_llm_output_path}\")\n",
    "    raise FileNotFoundError(f\"JSON íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {json_llm_output_path}\")\n",
    "\n",
    "print(\"=\" * 80 + \"\\n\")\n",
    "\n",
    "# ========================================\n",
    "# TTS íŒŒì´í”„ë¼ì¸ ì‹¤í–‰\n",
    "# ========================================\n",
    "\n",
    "print(\"[TTS] JSON ê¸°ë°˜ TTS íŒŒì´í”„ë¼ì¸ ì‹œì‘\")\n",
    "print(f\"  JSON ì„¸íŠ¸ íŒŒì¼: {json_llm_output_path}\")\n",
    "print(f\"  ì›ë³¸ ì˜ìƒ: {local_video_path}\")\n",
    "print(f\"  ìºìŠ¤í„° ì°¸ì¡°: {CASTER_REF_WAVS}\")\n",
    "print(f\"  í•´ì„¤ ì°¸ì¡° ({selected_analyst_name}): {ANALYST_REF_WAVS}\")\n",
    "print()\n",
    "\n",
    "try:\n",
    "    final_tts_wav, aligned_csv, tts_csv_with_paths = run_full_tts_pipeline_from_json(\n",
    "        json_sets_path=json_llm_output_path,\n",
    "        video_path=local_video_path,\n",
    "        caster_ref_wavs=CASTER_REF_WAVS,\n",
    "        analyst_ref_wavs=ANALYST_REF_WAVS,\n",
    "        fish_api_url=FISH_API_URL,\n",
    "        # ì•„ë˜ íŒŒë¼ë¯¸í„°ë“¤ì€ ê¸°ì¡´ ì…‹ì—… ê·¸ëŒ€ë¡œ ì‚¬ìš© (í•„ìš”í•˜ë©´ íŠœë‹ ê°€ëŠ¥)\n",
    "        min_text_chars=2,\n",
    "        merge_same_role=True,\n",
    "        merge_gap_thresh_sec=0.25,\n",
    "        merge_short_thresh_sec=1.0,\n",
    "        min_gap_sec=0.02,\n",
    "        caster_extra_ratio=0.2,\n",
    "        analyst_extra_ratio=2.0,\n",
    "        max_analyst_expand_sec=7.0,\n",
    "        analyst_priority_min_overlap_sec=0.5,\n",
    "        min_gap_ms=60,\n",
    "        tail_margin_ms=80,\n",
    "        caster_max_speedup=1.3,\n",
    "        analyst_max_speedup=1.8,\n",
    "    )\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"âœ… JSON â†’ TTS â†’ ì •ë ¬ â†’ WSOLA ì „ì²´ ì™„ë£Œ!\")\n",
    "    print(\"=\" * 80)\n",
    "    print(f\"  - TTS CSV(with paths): {tts_csv_with_paths}\")\n",
    "    print(f\"  - ì •ë ¬ CSV: {aligned_csv}\")\n",
    "    print(f\"  - ìµœì¢… TTS íƒ€ì„ë¼ì¸ wav: {final_tts_wav}\")\n",
    "    print(\"=\" * 80 + \"\\n\")\n",
    "\n",
    "    # í†µê³„ ì¶œë ¥\n",
    "    tts_df = pd.read_csv(tts_csv_with_paths)\n",
    "    print(\"ğŸ“Š TTS í†µê³„:\")\n",
    "    print(f\"  - ì´ ë°œí™” ìˆ˜: {len(tts_df)}\")\n",
    "    print(f\"  - TTS ì„±ê³µ: {tts_df['tts_wav_path'].notna().sum()}ê°œ\")\n",
    "    print(f\"  - TTS ì‹¤íŒ¨: {tts_df['tts_wav_path'].isna().sum()}ê°œ\")\n",
    "    \n",
    "    # ì—­í• ë³„ í†µê³„\n",
    "    if 'role' in tts_df.columns:\n",
    "        print(f\"\\nğŸ“Š ì—­í• ë³„ í†µê³„:\")\n",
    "        role_counts = tts_df['role'].value_counts()\n",
    "        for role, count in role_counts.items():\n",
    "            print(f\"  - {role}: {count}ê°œ\")\n",
    "            \n",
    "    print(f\"\\nğŸ™ï¸ ì‚¬ìš©ëœ í•´ì„¤ìœ„ì›: {selected_analyst_name}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\nâŒ JSON ê¸°ë°˜ TTS íŒŒì´í”„ë¼ì¸ ì‹¤íŒ¨: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "480757d1-335b-4dd0-9785-7c21002c0241",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# Cell 12: ìµœì¢… ì˜ìƒ ì¸ì½”ë”© (ì´ˆê³ ì† ìµœì í™” ë²„ì „)\n",
    "# ==========================================\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "import time\n",
    "\n",
    "OUTPUT_VIDEO_DIR = DATA_DIR / \"output_videos\"\n",
    "OUTPUT_VIDEO_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "TTS_AUDIO_DIR = DATA_DIR / \"tts_audio\" / video_stem\n",
    "AUDIO_SEPARATOR_DIR = DATA_DIR / \"audio_separator\"\n",
    "\n",
    "final_tts_wav = TTS_AUDIO_DIR / f\"{video_stem}.tts_timeline.wav\"\n",
    "no_vocals_path = AUDIO_SEPARATOR_DIR / \"no_vocals.wav\"\n",
    "\n",
    "def get_duration(file_path: Path) -> float:\n",
    "    \"\"\"íŒŒì¼ì˜ ê¸¸ì´ë¥¼ ì´ˆ ë‹¨ìœ„ë¡œ ë°˜í™˜\"\"\"\n",
    "    cmd = [\n",
    "        'ffprobe', '-v', 'error',\n",
    "        '-show_entries', 'format=duration',\n",
    "        '-of', 'default=noprint_wrappers=1:nokey=1',\n",
    "        str(file_path)\n",
    "    ]\n",
    "    result = subprocess.run(cmd, capture_output=True, encoding='utf-8', errors='replace', check=True)\n",
    "    return float(result.stdout.strip())\n",
    "\n",
    "def merge_audio_and_encode_video_fast(\n",
    "    original_video_path: Path,\n",
    "    tts_vocals_path: Path,\n",
    "    bg_no_vocals_path: Path,\n",
    "    output_video_path: Path,\n",
    "    tts_volume: float = 1.0,\n",
    "    bg_volume: float = 0.7,\n",
    ") -> Path:\n",
    "    \"\"\"\n",
    "    ì´ˆê³ ì† ë²„ì „: ì˜¤ë””ì˜¤ ë¨¼ì € ë¯¹ì‹± í›„ ë¹„ë””ì˜¤ì™€ ê²°í•©\n",
    "    \"\"\"\n",
    "    output_video_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"ğŸ“ íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    files_to_check = {\n",
    "        \"ì›ë³¸ ë¹„ë””ì˜¤\": original_video_path,\n",
    "        \"TTS ì˜¤ë””ì˜¤\": tts_vocals_path,\n",
    "        \"ë°°ê²½ìŒ\": bg_no_vocals_path,\n",
    "    }\n",
    "    \n",
    "    for name, path in files_to_check.items():\n",
    "        if path.exists():\n",
    "            size_mb = path.stat().st_size / (1024**2)\n",
    "            print(f\"âœ… {name}: {path.name} ({size_mb:.2f} MB)\")\n",
    "        else:\n",
    "            print(f\"âŒ {name}: {path}\")\n",
    "            raise FileNotFoundError(f\"{name} íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {path}\")\n",
    "    \n",
    "    print(\"=\" * 80 + \"\\n\")\n",
    "    \n",
    "    # íŒŒì¼ ê¸¸ì´ í™•ì¸\n",
    "    try:\n",
    "        video_duration = get_duration(original_video_path)\n",
    "        tts_duration = get_duration(tts_vocals_path)\n",
    "        bg_duration = get_duration(bg_no_vocals_path)\n",
    "        \n",
    "        print(f\"[INFO] ğŸ“¹ ë¹„ë””ì˜¤: {video_duration:.2f}ì´ˆ ({int(video_duration//60)}ë¶„ {int(video_duration%60)}ì´ˆ)\")\n",
    "        print(f\"[INFO] ğŸ¤ TTS: {tts_duration:.2f}ì´ˆ ({int(tts_duration//60)}ë¶„ {int(tts_duration%60)}ì´ˆ)\")\n",
    "        print(f\"[INFO] ğŸµ ë°°ê²½ìŒ: {bg_duration:.2f}ì´ˆ ({int(bg_duration//60)}ë¶„ {int(bg_duration%60)}ì´ˆ)\\n\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"[WARNING] íŒŒì¼ ê¸¸ì´ í™•ì¸ ì‹¤íŒ¨: {e}\\n\")\n",
    "    \n",
    "    # ============================================\n",
    "    # STEP 1: ì˜¤ë””ì˜¤ë§Œ ë¨¼ì € ë¹ ë¥´ê²Œ ë¯¹ì‹± (í•„í„° ì—†ì´)\n",
    "    # ============================================\n",
    "    temp_mixed_audio = output_video_path.parent / f\"temp_mixed_{output_video_path.stem}.m4a\"\n",
    "    \n",
    "    print(\"[STEP 1/2] ğŸµ ì˜¤ë””ì˜¤ ë¯¹ì‹± (ì´ˆê³ ì† ëª¨ë“œ)\")\n",
    "    start_step1 = time.time()\n",
    "    \n",
    "    # ì˜¤ë””ì˜¤ë§Œ ì²˜ë¦¬í•˜ë¯€ë¡œ ë§¤ìš° ë¹ ë¦„\n",
    "    audio_cmd = [\n",
    "        'ffmpeg', '-y',\n",
    "        '-i', str(tts_vocals_path),\n",
    "        '-i', str(bg_no_vocals_path),\n",
    "        '-filter_complex',\n",
    "        f'[0:a]volume={tts_volume}[a1];'\n",
    "        f'[1:a]volume={bg_volume}[a2];'\n",
    "        f'[a1][a2]amix=inputs=2:duration=first:dropout_transition=0[aout]',\n",
    "        '-map', '[aout]',\n",
    "        '-c:a', 'aac',\n",
    "        '-b:a', '192k',\n",
    "        str(temp_mixed_audio)\n",
    "    ]\n",
    "    \n",
    "    result = subprocess.run(audio_cmd, capture_output=True, encoding='utf-8', errors='replace')\n",
    "    \n",
    "    if result.returncode != 0:\n",
    "        print(f\"âŒ ì˜¤ë””ì˜¤ ë¯¹ì‹± ì‹¤íŒ¨: {result.stderr}\")\n",
    "        raise subprocess.CalledProcessError(result.returncode, audio_cmd)\n",
    "    \n",
    "    elapsed_step1 = time.time() - start_step1\n",
    "    print(f\"          âœ… ì™„ë£Œ ({elapsed_step1:.1f}ì´ˆ)\\n\")\n",
    "    \n",
    "    # ============================================\n",
    "    # STEP 2: ë¹„ë””ì˜¤ì™€ ì˜¤ë””ì˜¤ ê²°í•© (ë‘˜ ë‹¤ copy)\n",
    "    # ============================================\n",
    "    print(\"[STEP 2/2] ğŸ¬ ë¹„ë””ì˜¤ + ì˜¤ë””ì˜¤ ê²°í•© (ì´ˆê³ ì† ëª¨ë“œ)\")\n",
    "    start_step2 = time.time()\n",
    "    \n",
    "    # ë¹„ë””ì˜¤ì™€ ì˜¤ë””ì˜¤ ëª¨ë‘ ë³µì‚¬ë§Œ í•˜ë¯€ë¡œ ì´ˆê³ ì†\n",
    "    video_cmd = [\n",
    "        'ffmpeg', '-y',\n",
    "        '-i', str(original_video_path),\n",
    "        '-i', str(temp_mixed_audio),\n",
    "        '-map', '0:v:0',      # ë¹„ë””ì˜¤ ìŠ¤íŠ¸ë¦¼\n",
    "        '-map', '1:a:0',      # ì˜¤ë””ì˜¤ ìŠ¤íŠ¸ë¦¼\n",
    "        '-c:v', 'copy',       # ë¹„ë””ì˜¤ ë³µì‚¬ (ì¬ì¸ì½”ë”© ì—†ìŒ)\n",
    "        '-c:a', 'copy',       # ì˜¤ë””ì˜¤ ë³µì‚¬ (ì¬ì¸ì½”ë”© ì—†ìŒ)\n",
    "        '-shortest',\n",
    "        str(output_video_path)\n",
    "    ]\n",
    "    \n",
    "    result = subprocess.run(video_cmd, capture_output=True, encoding='utf-8', errors='replace')\n",
    "    \n",
    "    if result.returncode != 0:\n",
    "        print(f\"âŒ ë¹„ë””ì˜¤ ê²°í•© ì‹¤íŒ¨: {result.stderr}\")\n",
    "        raise subprocess.CalledProcessError(result.returncode, video_cmd)\n",
    "    \n",
    "    elapsed_step2 = time.time() - start_step2\n",
    "    print(f\"          âœ… ì™„ë£Œ ({elapsed_step2:.1f}ì´ˆ)\\n\")\n",
    "    \n",
    "    # ì„ì‹œ íŒŒì¼ ì‚­ì œ\n",
    "    try:\n",
    "        temp_mixed_audio.unlink()\n",
    "        print(f\"[CLEANUP] ğŸ—‘ï¸  ì„ì‹œ íŒŒì¼ ì‚­ì œ\\n\")\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    total_time = elapsed_step1 + elapsed_step2\n",
    "    print(f\"[TOTAL] âš¡ ì „ì²´ ì†Œìš” ì‹œê°„: {total_time:.1f}ì´ˆ\")\n",
    "    \n",
    "    return output_video_path\n",
    "\n",
    "# ìµœì¢… ì¶œë ¥ ì˜ìƒ ê²½ë¡œ\n",
    "final_video_path = OUTPUT_VIDEO_DIR / f\"{video_stem}.final.mp4\"\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"ğŸ¬ ìµœì¢… ì˜ìƒ ìƒì„± ì‹œì‘ (ì´ˆê³ ì† ëª¨ë“œ)\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"  ğŸ“¹ ì›ë³¸ ë¹„ë””ì˜¤: {local_video_path.name}\")\n",
    "print(f\"  ğŸ¤ TTS ìŒì„±: {final_tts_wav.name}\")\n",
    "print(f\"  ğŸµ ë°°ê²½ìŒ: {no_vocals_path.name}\")\n",
    "print(f\"  ğŸ’¾ ì¶œë ¥: {final_video_path.name}\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "try:\n",
    "    final_video = merge_audio_and_encode_video_fast(\n",
    "        original_video_path=local_video_path,\n",
    "        tts_vocals_path=final_tts_wav,\n",
    "        bg_no_vocals_path=no_vocals_path,\n",
    "        output_video_path=final_video_path,\n",
    "        tts_volume=1.0,\n",
    "        bg_volume=0.7,\n",
    "    )\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"ğŸ‰ ì „ì²´ íŒŒì´í”„ë¼ì¸ ì™„ë£Œ!\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"âœ… ìµœì¢… ì˜ìƒ: {final_video}\")\n",
    "    print(f\"ğŸ“¦ íŒŒì¼ í¬ê¸°: {final_video.stat().st_size / (1024**2):.2f} MB\")\n",
    "    \n",
    "    # ìµœì¢… ì˜ìƒ ê¸¸ì´ í™•ì¸\n",
    "    try:\n",
    "        final_duration = get_duration(final_video)\n",
    "        print(f\"â±ï¸  ì˜ìƒ ê¸¸ì´: {final_duration:.2f}ì´ˆ ({int(final_duration//60)}ë¶„ {int(final_duration%60)}ì´ˆ)\")\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    print(\"=\"*80 + \"\\n\")\n",
    "    \n",
    "except subprocess.CalledProcessError as e:\n",
    "    print(f\"\\nâŒ ì¸ì½”ë”© ì‹¤íŒ¨!\")\n",
    "    print(f\"ì—ëŸ¬ ì½”ë“œ: {e.returncode}\")\n",
    "    raise\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\nâŒ ì‹¤íŒ¨: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "    raise"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "skn17_final_env (Runpod)",
   "language": "python",
   "name": "skn17_final_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
