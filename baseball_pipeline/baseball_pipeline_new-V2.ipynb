{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d990f33d-370f-4062-810d-f5e2330e6041",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting audio_separator\n",
      "  Downloading audio_separator-0.40.0-py3-none-any.whl.metadata (36 kB)\n",
      "Collecting beartype<0.19.0,>=0.18.5 (from audio_separator)\n",
      "  Downloading beartype-0.18.5-py3-none-any.whl.metadata (30 kB)\n",
      "Collecting diffq>=0.2 (from audio_separator)\n",
      "  Downloading diffq-0.2.4.tar.gz (157 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting einops>=0.7 (from audio_separator)\n",
      "  Using cached einops-0.8.1-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting julius>=0.2 (from audio_separator)\n",
      "  Using cached julius-0.2.7.tar.gz (59 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting librosa>=0.10 (from audio_separator)\n",
      "  Using cached librosa-0.11.0-py3-none-any.whl.metadata (8.7 kB)\n",
      "Collecting ml_collections (from audio_separator)\n",
      "  Downloading ml_collections-1.1.0-py3-none-any.whl.metadata (22 kB)\n",
      "Requirement already satisfied: numpy>=2 in /usr/local/lib/python3.12/dist-packages (from audio_separator) (2.1.2)\n",
      "Collecting onnx-weekly (from audio_separator)\n",
      "  Downloading onnx_weekly-1.21.0.dev20251208-cp312-abi3-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (8.6 kB)\n",
      "Collecting onnx2torch-py313>=1.6 (from audio_separator)\n",
      "  Downloading onnx2torch_py313-1.6.0-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting pydub>=0.25 (from audio_separator)\n",
      "  Using cached pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from audio_separator) (6.0.3)\n",
      "Requirement already satisfied: requests>=2 in /usr/local/lib/python3.12/dist-packages (from audio_separator) (2.32.5)\n",
      "Collecting resampy>=0.4 (from audio_separator)\n",
      "  Using cached resampy-0.4.3-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting rotary-embedding-torch<0.7.0,>=0.6.1 (from audio_separator)\n",
      "  Downloading rotary_embedding_torch-0.6.5-py3-none-any.whl.metadata (678 bytes)\n",
      "Collecting samplerate==0.1.0 (from audio_separator)\n",
      "  Downloading samplerate-0.1.0-py2.py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting scipy<2.0.0,>=1.13.0 (from audio_separator)\n",
      "  Downloading scipy-1.16.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (62 kB)\n",
      "Requirement already satisfied: six>=1.16 in /usr/lib/python3/dist-packages (from audio_separator) (1.16.0)\n",
      "Collecting soundfile>=0.12 (from audio_separator)\n",
      "  Using cached soundfile-0.13.1-py2.py3-none-manylinux_2_28_x86_64.whl.metadata (16 kB)\n",
      "Requirement already satisfied: torch>=2.3 in /usr/local/lib/python3.12/dist-packages (from audio_separator) (2.8.0+cu128)\n",
      "Collecting tqdm (from audio_separator)\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: cffi>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from samplerate==0.1.0->audio_separator) (2.0.0)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.0.0->samplerate==0.1.0->audio_separator) (2.23)\n",
      "Collecting Cython (from diffq>=0.2->audio_separator)\n",
      "  Using cached cython-3.2.2-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (5.0 kB)\n",
      "Collecting audioread>=2.1.9 (from librosa>=0.10->audio_separator)\n",
      "  Using cached audioread-3.1.0-py3-none-any.whl.metadata (9.0 kB)\n",
      "Collecting numba>=0.51.0 (from librosa>=0.10->audio_separator)\n",
      "  Downloading numba-0.62.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.8 kB)\n",
      "Collecting scikit-learn>=1.1.0 (from librosa>=0.10->audio_separator)\n",
      "  Downloading scikit_learn-1.7.2-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (11 kB)\n",
      "Collecting joblib>=1.0 (from librosa>=0.10->audio_separator)\n",
      "  Using cached joblib-1.5.2-py3-none-any.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.12/dist-packages (from librosa>=0.10->audio_separator) (5.2.1)\n",
      "Collecting pooch>=1.1 (from librosa>=0.10->audio_separator)\n",
      "  Using cached pooch-1.8.2-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting soxr>=0.3.2 (from librosa>=0.10->audio_separator)\n",
      "  Downloading soxr-1.0.0-cp312-abi3-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: typing_extensions>=4.1.1 in /usr/local/lib/python3.12/dist-packages (from librosa>=0.10->audio_separator) (4.15.0)\n",
      "Collecting lazy_loader>=0.1 (from librosa>=0.10->audio_separator)\n",
      "  Using cached lazy_loader-0.4-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting msgpack>=1.0 (from librosa>=0.10->audio_separator)\n",
      "  Downloading msgpack-1.1.2-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (8.1 kB)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from lazy_loader>=0.1->librosa>=0.10->audio_separator) (25.0)\n",
      "Collecting llvmlite<0.46,>=0.45.0dev0 (from numba>=0.51.0->librosa>=0.10->audio_separator)\n",
      "  Downloading llvmlite-0.45.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (4.9 kB)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from onnx2torch-py313>=1.6->audio_separator) (0.23.0+cu128)\n",
      "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from pooch>=1.1->librosa>=0.10->audio_separator) (4.5.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2->audio_separator) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2->audio_separator) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2->audio_separator) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2->audio_separator) (2025.10.5)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn>=1.1.0->librosa>=0.10->audio_separator)\n",
      "  Using cached threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=2.3->audio_separator) (3.20.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.3->audio_separator) (80.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.3->audio_separator) (1.13.3)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=2.3->audio_separator) (3.3)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.3->audio_separator) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=2.3->audio_separator) (2024.6.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch>=2.3->audio_separator) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch>=2.3->audio_separator) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch>=2.3->audio_separator) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.3->audio_separator) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.3->audio_separator) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /usr/local/lib/python3.12/dist-packages (from torch>=2.3->audio_separator) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /usr/local/lib/python3.12/dist-packages (from torch>=2.3->audio_separator) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /usr/local/lib/python3.12/dist-packages (from torch>=2.3->audio_separator) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /usr/local/lib/python3.12/dist-packages (from torch>=2.3->audio_separator) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.3->audio_separator) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.3->audio_separator) (2.27.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch>=2.3->audio_separator) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch>=2.3->audio_separator) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.3->audio_separator) (1.13.1.3)\n",
      "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.3->audio_separator) (3.4.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.3->audio_separator) (1.3.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision>=0.9.0->onnx2torch-py313>=1.6->audio_separator) (11.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.3->audio_separator) (3.0.3)\n",
      "Collecting absl-py (from ml_collections->audio_separator)\n",
      "  Using cached absl_py-2.3.1-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting protobuf>=4.25.1 (from onnx-weekly->audio_separator)\n",
      "  Downloading protobuf-6.33.2-cp39-abi3-manylinux2014_x86_64.whl.metadata (593 bytes)\n",
      "Collecting ml_dtypes>=0.5.0 (from onnx-weekly->audio_separator)\n",
      "  Downloading ml_dtypes-0.5.4-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (8.9 kB)\n",
      "Downloading audio_separator-0.40.0-py3-none-any.whl (385 kB)\n",
      "Downloading samplerate-0.1.0-py2.py3-none-any.whl (4.0 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m27.2 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading beartype-0.18.5-py3-none-any.whl (917 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m917.8/917.8 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading rotary_embedding_torch-0.6.5-py3-none-any.whl (5.5 kB)\n",
      "Downloading scipy-1.16.3-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (35.7 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m35.7/35.7 MB\u001b[0m \u001b[31m36.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m6m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached einops-0.8.1-py3-none-any.whl (64 kB)\n",
      "Using cached librosa-0.11.0-py3-none-any.whl (260 kB)\n",
      "Using cached audioread-3.1.0-py3-none-any.whl (23 kB)\n",
      "Using cached joblib-1.5.2-py3-none-any.whl (308 kB)\n",
      "Using cached lazy_loader-0.4-py3-none-any.whl (12 kB)\n",
      "Downloading msgpack-1.1.2-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (427 kB)\n",
      "Downloading numba-0.62.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.8 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m33.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading llvmlite-0.45.1-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (56.3 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m47.3 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0m6m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading onnx2torch_py313-1.6.0-py3-none-any.whl (81 kB)\n",
      "Using cached pooch-1.8.2-py3-none-any.whl (64 kB)\n",
      "Using cached pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
      "Using cached resampy-0.4.3-py3-none-any.whl (3.1 MB)\n",
      "Downloading scikit_learn-1.7.2-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (9.5 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m9.5/9.5 MB\u001b[0m \u001b[31m55.6 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached soundfile-0.13.1-py2.py3-none-manylinux_2_28_x86_64.whl (1.3 MB)\n",
      "Downloading soxr-1.0.0-cp312-abi3-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (238 kB)\n",
      "Using cached threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Using cached cython-3.2.2-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (3.4 MB)\n",
      "Downloading ml_collections-1.1.0-py3-none-any.whl (76 kB)\n",
      "Using cached absl_py-2.3.1-py3-none-any.whl (135 kB)\n",
      "Downloading onnx_weekly-1.21.0.dev20251208-cp312-abi3-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (18.1 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m18.1/18.1 MB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading ml_dtypes-0.5.4-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (5.0 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m5.0/5.0 MB\u001b[0m \u001b[31m28.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading protobuf-6.33.2-cp39-abi3-manylinux2014_x86_64.whl (323 kB)\n",
      "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Building wheels for collected packages: diffq, julius\n",
      "  Building wheel for diffq (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for diffq: filename=diffq-0.2.4-cp312-cp312-linux_x86_64.whl size=475513 sha256=808fb4021f2c63513a93d138b274b2c9a084283d09ce2e56593c66ed71a09f78\n",
      "  Stored in directory: /workspace/.cache/pip/wheels/e1/2d/ce/ffafea46a65fecd3c416036f48b3d93471cf47b8c9dcd50e60\n",
      "  Building wheel for julius (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for julius: filename=julius-0.2.7-py3-none-any.whl size=21966 sha256=69a7450a20a195cd75dc1dc1a9b2e309f9e8543b4b4eb4cbb68eb7fdb1de5a49\n",
      "  Stored in directory: /workspace/.cache/pip/wheels/de/c1/ca/544dafe48401e8e2e17064dfe465a390fca9e8720ffa12e744\n",
      "Successfully built diffq julius\n",
      "Installing collected packages: pydub, tqdm, threadpoolctl, soxr, scipy, protobuf, msgpack, ml_dtypes, llvmlite, lazy_loader, joblib, einops, Cython, beartype, audioread, absl-py, soundfile, scikit-learn, samplerate, pooch, onnx-weekly, numba, ml_collections, resampy, librosa, rotary-embedding-torch, julius, diffq, onnx2torch-py313, audio_separator\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m30/30\u001b[0m [audio_separator] [audio_separator]\n",
      "\u001b[1A\u001b[2KSuccessfully installed Cython-3.2.2 absl-py-2.3.1 audio_separator-0.40.0 audioread-3.1.0 beartype-0.18.5 diffq-0.2.4 einops-0.8.1 joblib-1.5.2 julius-0.2.7 lazy_loader-0.4 librosa-0.11.0 llvmlite-0.45.1 ml_collections-1.1.0 ml_dtypes-0.5.4 msgpack-1.1.2 numba-0.62.1 onnx-weekly-1.21.0.dev20251208 onnx2torch-py313-1.6.0 pooch-1.8.2 protobuf-6.33.2 pydub-0.25.1 resampy-0.4.3 rotary-embedding-torch-0.6.5 samplerate-0.1.0 scikit-learn-1.7.2 scipy-1.16.3 soundfile-0.13.1 soxr-1.0.0 threadpoolctl-3.6.0 tqdm-4.67.1\n",
      "Collecting bitsandbytes\n",
      "  Downloading bitsandbytes-0.48.2-py3-none-manylinux_2_24_x86_64.whl.metadata (10 kB)\n",
      "Requirement already satisfied: torch<3,>=2.3 in /usr/local/lib/python3.12/dist-packages (from bitsandbytes) (2.8.0+cu128)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from bitsandbytes) (2.1.2)\n",
      "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from bitsandbytes) (25.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (3.20.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (4.15.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (80.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (1.13.3)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (3.3)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (2024.6.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (2.27.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (1.13.1.3)\n",
      "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch<3,>=2.3->bitsandbytes) (3.4.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch<3,>=2.3->bitsandbytes) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch<3,>=2.3->bitsandbytes) (3.0.3)\n",
      "Downloading bitsandbytes-0.48.2-py3-none-manylinux_2_24_x86_64.whl (59.4 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m59.4/59.4 MB\u001b[0m \u001b[31m46.7 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0m6m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: bitsandbytes\n",
      "Successfully installed bitsandbytes-0.48.2\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# Cell 0 : ì¶”ê°€ íŒ¨í‚¤ì§€ ì„¤ì¹˜\n",
    "# ==========================================\n",
    "\n",
    "# ì„¤ì¹˜ë¥¼ í–ˆëŠ”ë° ì…€ 3ë²ˆ 7ë²ˆì—ì„œ ì‘ë™ì´ ì•ˆ ë  ê²½ìš° í„°ë¯¸ë„ì—ì„œ skn17_final_env ì»¤ë„ì´ ì—°ê²°ë˜ì–´ ìˆëŠ” ìƒí™©ì—ì„œ ì„¤ì¹˜\n",
    "!pip install audio_separator\n",
    "!pip install -U bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4609630d-dfd6-4526-8d10-4ce34c1ccf0b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROJECT_ROOT: /workspace/baseball_pipeline\n",
      "\n",
      "âœ… ë””ë ‰í† ë¦¬ ìƒì„± ì™„ë£Œ\n",
      "âœ… API í† í° ì„¤ì • ì™„ë£Œ\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# Cell 1: ê²½ë¡œ ì„¤ì • ë° í† í° í™œì„±í™”\n",
    "# ==========================================\n",
    "\n",
    "from pathlib import Path\n",
    "import os, sys\n",
    "import json\n",
    "\n",
    "# ---- í”„ë¡œì íŠ¸ ë£¨íŠ¸ ----\n",
    "PROJECT_ROOT = Path(\"/workspace/baseball_pipeline\")\n",
    "os.chdir(PROJECT_ROOT)\n",
    "\n",
    "if str(PROJECT_ROOT) not in sys.path:\n",
    "    sys.path.append(str(PROJECT_ROOT))\n",
    "\n",
    "print(\"PROJECT_ROOT:\", PROJECT_ROOT)\n",
    "\n",
    "# ---- ë°ì´í„° ë””ë ‰í† ë¦¬ ----\n",
    "from src import DATA_DIR, FAISS_DIR, FISH_ROOT\n",
    "\n",
    "INPUT_VIDEO_DIR = DATA_DIR / \"input_videos\"\n",
    "STT_RAW_DIR = DATA_DIR / \"stt_raw\"\n",
    "STT_SEG_DIR = DATA_DIR / \"stt_segments\"\n",
    "LLM_OUT_DIR = DATA_DIR / \"llm_outputs\"\n",
    "TTS_AUDIO_DIR = DATA_DIR / \"tts_audio\"\n",
    "OUTPUT_VIDEO_DIR = DATA_DIR / \"output_videos\"\n",
    "AUDIO_ROOT = DATA_DIR / \"audio_separator\"\n",
    "FRAMES_ROOT = DATA_DIR / \"frames\"\n",
    "SRC_ROOT = PROJECT_ROOT / \"src\"\n",
    "\n",
    "if str(SRC_ROOT) not in sys.path:\n",
    "    sys.path.append(str(SRC_ROOT))\n",
    "\n",
    "# ë””ë ‰í† ë¦¬ ìƒì„±\n",
    "for d in (DATA_DIR, INPUT_VIDEO_DIR, STT_RAW_DIR, STT_SEG_DIR, \n",
    "          LLM_OUT_DIR, TTS_AUDIO_DIR, OUTPUT_VIDEO_DIR, AUDIO_ROOT, \n",
    "          FRAMES_ROOT, FAISS_DIR, SRC_ROOT):\n",
    "    d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"\\nâœ… ë””ë ‰í† ë¦¬ ìƒì„± ì™„ë£Œ\")\n",
    "\n",
    "# ---- API í† í° ì„¤ì • ----\n",
    "CLOVA_INVOKE_URL = \"\"\n",
    "CLOVA_SECRET_KEY = \"\"\n",
    "\n",
    "HF_TOKEN = \"\"\n",
    "# OPENAI_API_KEY = \"sk-proj-...\"  # í•„ìš”ì‹œ ì…ë ¥\n",
    "\n",
    "if HF_TOKEN and \"xxx\" not in HF_TOKEN:\n",
    "    os.environ[\"HF_TOKEN\"] = HF_TOKEN\n",
    "    os.environ[\"HUGGINGFACE_HUB_TOKEN\"] = HF_TOKEN\n",
    "    os.environ[\"HUGGING_FACE_HUB_TOKEN\"] = HF_TOKEN\n",
    "\n",
    "# if OPENAI_API_KEY:\n",
    "#     os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY\n",
    "\n",
    "print(\"âœ… API í† í° ì„¤ì • ì™„ë£Œ\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ad4643c8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GDRIVE] file_id: 1kqN0IAerBH72RnoQwXzM-T-rrwoaMLDn\n",
      "[GDRIVE] url    : https://drive.google.com/uc?id=1kqN0IAerBH72RnoQwXzM-T-rrwoaMLDn\n",
      "[GDRIVE] output : /workspace/skn17_final_runpod_code/baseball_pipeline/data/input_videos/ì²´ì½”_ëŒ€í•œë¯¼êµ­_wbc.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=1kqN0IAerBH72RnoQwXzM-T-rrwoaMLDn\n",
      "From (redirected): https://drive.google.com/uc?id=1kqN0IAerBH72RnoQwXzM-T-rrwoaMLDn&confirm=t&uuid=69f2a8f3-c11d-49e4-b630-cc7d149a2e9b\n",
      "To: /workspace/skn17_final_runpod_code/baseball_pipeline/data/input_videos/ì²´ì½”_ëŒ€í•œë¯¼êµ­_wbc.mp4\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.29G/1.29G [00:25<00:00, 50.1MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GDRIVE] ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: /workspace/skn17_final_runpod_code/baseball_pipeline/data/input_videos/ì²´ì½”_ëŒ€í•œë¯¼êµ­_wbc.mp4\n",
      "\n",
      "âœ… ì˜ìƒ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ\n",
      "  video_stem: ì²´ì½”_ëŒ€í•œë¯¼êµ­_wbc\n",
      "  ê²½ë¡œ: /workspace/skn17_final_runpod_code/baseball_pipeline/data/input_videos/ì²´ì½”_ëŒ€í•œë¯¼êµ­_wbc.mp4\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from src.google_mp4_download import download_gdrive_video\n",
    "\n",
    "# ====== ì—¬ê¸°ì— êµ¬ê¸€ ë“œë¼ì´ë¸Œ ë§í¬ ì…ë ¥ ======\n",
    "gdrive_url = \"https://drive.google.com/file/d/1kqN0IAerBH72RnoQwXzM-T-rrwoaMLDn/view?usp=sharing\"\n",
    "VIDEO_NAME = \"ì²´ì½”_ëŒ€í•œë¯¼êµ­_wbc.mp4\"\n",
    "\n",
    "local_video_path = download_gdrive_video(gdrive_url, dest_name=VIDEO_NAME)\n",
    "video_stem = Path(VIDEO_NAME).stem\n",
    "\n",
    "print(f\"\\nâœ… ì˜ìƒ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ\")\n",
    "print(f\"  video_stem: {video_stem}\")\n",
    "print(f\"  ê²½ë¡œ: {local_video_path}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ce813e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-08 03:18:23,676 - INFO - separator - Separator version 0.40.0 instantiating with output_dir: /workspace/skn17_final_runpod_code/baseball_pipeline/data/audio_separator, output_format: wav\n",
      "2025-12-08 03:18:23,677 - INFO - separator - Using model directory from model_file_dir parameter: /workspace/skn17_final_runpod_code/baseball_pipeline/data/audio_separator/models\n",
      "2025-12-08 03:18:23,680 - INFO - separator - Operating System: Linux #63~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Tue Apr 22 19:00:15 UTC 2\n",
      "2025-12-08 03:18:23,681 - INFO - separator - System: Linux Node: f75de6caa909 Release: 6.8.0-60-generic Machine: x86_64 Proc: x86_64\n",
      "2025-12-08 03:18:23,681 - INFO - separator - Python Version: 3.10.19\n",
      "2025-12-08 03:18:23,682 - INFO - separator - PyTorch Version: 2.5.1+cu121\n",
      "2025-12-08 03:18:23,737 - INFO - separator - FFmpeg installed: ffmpeg version 6.1.1-3ubuntu5 Copyright (c) 2000-2023 the FFmpeg developers\n",
      "2025-12-08 03:18:23,749 - INFO - separator - ONNX Runtime CPU package installed with version: 1.23.2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ì˜¤ë””ì˜¤ ë¶„ë¦¬ ì‹œì‘: /workspace/skn17_final_runpod_code/baseball_pipeline/data/input_videos/ì²´ì½”_ëŒ€í•œë¯¼êµ­_wbc.mp4\n",
      "  ì‚¬ìš© ëª¨ë¸: model_bs_roformer_ep_317_sdr_12.9755.ckpt (BS-RoFormer-ViperX)\n",
      "  ì‹¤í–‰ ì¥ì¹˜: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-08 03:18:23,903 - INFO - separator - CUDA is available in Torch, setting Torch device to CUDA\n",
      "2025-12-08 03:18:23,904 - WARNING - separator - CUDAExecutionProvider not available in ONNXruntime, so acceleration will NOT be enabled\n",
      "2025-12-08 03:18:23,905 - INFO - separator - Loading model model_bs_roformer_ep_317_sdr_12.9755.ckpt...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  >> ëª¨ë¸ ë¡œë”© ì¤‘... (ìµœì´ˆ ì‹¤í–‰ ì‹œ ë‹¤ìš´ë¡œë“œì— ì‹œê°„ì´ ì†Œìš”ë©ë‹ˆë‹¤)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "28.3kiB [00:00, 1.43MiB/s]                  \n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 639M/639M [00:13<00:00, 48.0MiB/s] \n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2.27k/2.27k [00:00<00:00, 217kiB/s]\n",
      "2025-12-08 03:18:49,418 - INFO - mdxc_separator - MDXC Separator initialisation complete\n",
      "2025-12-08 03:18:49,420 - INFO - separator - Roformer loading stats: {'new_implementation_success': 1, 'total_failures': 0}\n",
      "2025-12-08 03:18:49,420 - INFO - separator - Load model duration: 00:00:25\n",
      "2025-12-08 03:18:49,427 - INFO - separator - Processing file: /workspace/skn17_final_runpod_code/baseball_pipeline/data/input_videos/ì²´ì½”_ëŒ€í•œë¯¼êµ­_wbc.mp4\n",
      "2025-12-08 03:18:49,428 - INFO - separator - Starting separation process for audio_file_path: /workspace/skn17_final_runpod_code/baseball_pipeline/data/input_videos/ì²´ì½”_ëŒ€í•œë¯¼êµ­_wbc.mp4\n",
      "2025-12-08 03:18:49,565 - WARNING - common_separator - Could not read audio file info, defaulting to 16-bit output: Error opening '/workspace/skn17_final_runpod_code/baseball_pipeline/data/input_videos/ì²´ì½”_ëŒ€í•œë¯¼êµ­_wbc.mp4': Format not recognised.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  >> ë¶„ë¦¬ ì‘ì—… ìˆ˜í–‰ ì¤‘...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|â–Œ         | 92/1576 [01:26<23:17,  1.06it/s]"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# Cell 3: audio_separator ìŒì„± ë¶„ë¦¬\n",
    "# ==========================================\n",
    "from src.audio_separator import separate_audio_sota\n",
    "\n",
    "track_dict = separate_audio_sota(\n",
    "    video_path=str(local_video_path),\n",
    "    output_dir=str(AUDIO_ROOT),\n",
    "    device=\"cuda\"\n",
    ")\n",
    "\n",
    "vocals_path = track_dict[\"vocals\"]\n",
    "no_vocals_path = track_dict[\"no_vocals\"]\n",
    "\n",
    "print(f\"\\nâœ… ìŒì„± ë¶„ë¦¬ ì™„ë£Œ! (SOTA Performance)\")\n",
    "print(f\"  - í•´ì„¤(Vocals)    : {vocals_path}\")\n",
    "print(f\"  - í˜„ì¥ìŒ(No Vocals): {no_vocals_path}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a63c9a0-e8a4-477a-a306-69b70ec20b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# Cell 4: STT (Clova Speech API)\n",
    "# ==========================================\n",
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "from src.stt_pipeline import run_stt_pipeline\n",
    "from src.stt_event_splitter import stt_json_to_event_sets\n",
    "\n",
    "print(f\"[STT] Clova STT ì‹œì‘\")\n",
    "print(f\"  ì…ë ¥: {vocals_path}\")\n",
    "\n",
    "STT_KEYWORD_XLSX = PROJECT_ROOT / \"stt.xlsx\"\n",
    "if STT_KEYWORD_XLSX.exists():\n",
    "    xlsx_path = STT_KEYWORD_XLSX\n",
    "    use_domain = False\n",
    "    print(\"  í‚¤ì›Œë“œ: stt.xlsx ì‚¬ìš© (ì—‘ì…€ ë¶€ìŠ¤íŒ…)\")\n",
    "else:\n",
    "    xlsx_path = None\n",
    "    use_domain = True\n",
    "    print(\"  í‚¤ì›Œë“œ: ë„ë©”ì¸ ë¶€ìŠ¤íŒ…ë§Œ ì‚¬ìš©\")\n",
    "\n",
    "# ---- STT íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ----\n",
    "timeline_json_path = run_stt_pipeline(\n",
    "    audio_path=vocals_path,\n",
    "    invoke_url=CLOVA_INVOKE_URL,\n",
    "    secret_key=CLOVA_SECRET_KEY,\n",
    "    stt_raw_dir=STT_RAW_DIR,\n",
    "    stt_seg_dir=STT_SEG_DIR,\n",
    "    xlsx_keywords_path=xlsx_path,\n",
    "    use_domain_boostings=use_domain,\n",
    "    speaker_count_min=2,\n",
    "    speaker_count_max=3,\n",
    "    save_raw_json=True,\n",
    "    pause_thresh_ms=50000,  # í•„ìš”ì‹œ ì¡°ì ˆ\n",
    ")\n",
    "\n",
    "print(f\"\\nâœ… STT ì™„ë£Œ!\")\n",
    "print(f\"timeline.json : {timeline_json_path}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4901fa9b-4f60-4f09-a783-8c0764eed938",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# Cell 5: STT ë°ì´í„° ì „ì²˜ë¦¬ (ì´ë²¤íŠ¸ ì„¸íŠ¸)\n",
    "# ==========================================\n",
    "from src.stt_event_splitter import stt_json_to_event_sets\n",
    "\n",
    "timeline_json_stem = timeline_json_path.stem\n",
    "# ê°™ì€ ë””ë ‰í„°ë¦¬ì— *_output.json ìœ¼ë¡œ ì €ì¥\n",
    "json_after_split_path = timeline_json_path.with_name(f\"{timeline_json_stem}_set_split.json\")\n",
    "\n",
    "# ì…ë ¥ JSON ë¡œë“œ\n",
    "with timeline_json_path.open(\"r\", encoding=\"utf-8\") as f:\n",
    "    stt_json = json.load(f)\n",
    "\n",
    "# ì´ë²¤íŠ¸ ì„¸íŠ¸ ë³€í™˜\n",
    "event_sets = stt_json_to_event_sets(\n",
    "    stt_json,\n",
    "    caster_gap=10.0,   # í•„ìš”ì‹œ íŠœë‹\n",
    "    silence_gap=2.0,  # í•„ìš”ì‹œ íŠœë‹\n",
    ")\n",
    "\n",
    "print(f\"ì´ë²¤íŠ¸ ì„¸íŠ¸ ê°œìˆ˜: {len(event_sets)}\")\n",
    "\n",
    "# ì¶œë ¥ JSON ì €ì¥\n",
    "with json_after_split_path.open(\"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(event_sets, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"ì €ì¥ ì™„ë£Œ: {json_after_split_path.resolve()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e28a5f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# Cell 6: ì˜ìƒ ì´ë¯¸ì§€ ì¶”ì¶œ\n",
    "# ==========================================\n",
    "\n",
    "import json\n",
    "\n",
    "from src.image_extraction import capture_frames_for_sets\n",
    "\n",
    "# ì„¸íŠ¸ json ë¡œë“œ\n",
    "with json_after_split_path.open(\"r\", encoding=\"utf-8\") as f:\n",
    "    sets = json.load(f)   # ë¦¬ìŠ¤íŠ¸ í˜•íƒœì—¬ì•¼ í•¨\n",
    "\n",
    "print(f\"ì„¸íŠ¸ ê°œìˆ˜: {len(sets)}\")\n",
    "\n",
    "# 5) ì„¸íŠ¸ì˜ set_start_sec ê¸°ì¤€ìœ¼ë¡œ ì´ë¯¸ì§€ ì¶”ì¶œ\n",
    "results = capture_frames_for_sets(\n",
    "    video_path=local_video_path,\n",
    "    sets=sets,\n",
    "    output_dir=FRAMES_ROOT\n",
    ")\n",
    "\n",
    "# 6) ìš”ì•½ ì¶œë ¥\n",
    "success_count = sum(1 for r in results if r[\"success\"])\n",
    "print(f\"ì„±ê³µì ìœ¼ë¡œ ì €ì¥ëœ ì´ë¯¸ì§€ ìˆ˜: {success_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da221745-5dd7-4ca0-8b3b-5dc889a719cb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# Cell 7: VLM ìŠ¤ì½”ì–´ë³´ë“œ ì¶”ì¶œ (ìµœì í™” ë²„ì „)\n",
    "# ==========================================\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from src.vlm_scoreboard import (\n",
    "    load_scoreboard_model_and_processor,\n",
    "    attach_scoreboard_to_sets,\n",
    ")\n",
    "\n",
    "# ==========================\n",
    "# ëª¨ë¸ / í”„ë¡œì„¸ì„œ ë¡œë“œ\n",
    "# ==========================\n",
    "\n",
    "vlm_model, vlm_processor = load_scoreboard_model_and_processor()\n",
    "\n",
    "\n",
    "# ==========================\n",
    "# scoreboard íŒŒì´í”„ë¼ì¸ ì‹¤í–‰\n",
    "# ==========================\n",
    "json_after_split_stem = json_after_split_path.stem\n",
    "# ê°™ì€ ë””ë ‰í„°ë¦¬ì— *_output.json ìœ¼ë¡œ ì €ì¥\n",
    "scoreboard_json_path = json_after_split_path.with_name(f\"{json_after_split_stem}_scoreboard.json\")\n",
    "\n",
    "updated_sets = attach_scoreboard_to_sets(\n",
    "    json_after_split_path=json_after_split_path,\n",
    "    output_json_path=scoreboard_json_path,\n",
    "    frames_root=FRAMES_ROOT,\n",
    "    video_path=local_video_path,\n",
    "    model=vlm_model,\n",
    "    processor=vlm_processor,\n",
    "    retry_if_all_null=False,   # all-nullì´ë©´ +2ì´ˆ ì¬ì‹œë„\n",
    "    retry_offset_sec=2.0,\n",
    ")\n",
    "\n",
    "print(f\"ì´ ì„¸íŠ¸ ìˆ˜: {len(updated_sets)}\")\n",
    "print(f\"ì €ì¥ ì™„ë£Œ: {scoreboard_json_path.resolve()}\")\n",
    "\n",
    "# ì¼ë¶€ë§Œ ëˆˆìœ¼ë¡œ í™•ì¸\n",
    "for s in updated_sets[:5]:\n",
    "    print(\"=\" * 80)\n",
    "    print(\"set_id:\", s[\"set_id\"])\n",
    "    print(\"set_start_sec:\", s[\"set_start_sec\"])\n",
    "    print(\"scoreboard:\", s[\"scoreboard\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f579767-1d19-414c-84e6-3e6cc243223c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "# from pakchanho_commentary_generator import (\n",
    "#     load_pakchanho_model,\n",
    "#     generate_analyst_for_all_sets,\n",
    "# )\n",
    "\n",
    "from src.llm_generator import (\n",
    "    load_pakchanho_model,\n",
    "    generate_analyst_for_all_sets,\n",
    ")\n",
    "\n",
    "# Pakchanho LLM ì ìš© í›„ ì €ì¥í•  ê²½ë¡œ\n",
    "json_llm_output_path = LLM_OUT_DIR / \"vocals_timeline_set_split_scoreboard_pakchanho.json\"\n",
    "\n",
    "# 1) ëª¨ë¸ ë¡œë“œ\n",
    "model, tokenizer = load_pakchanho_model(\n",
    "    base_model_name=\"kakaocorp/kanana-1.5-8b-instruct-2505\",\n",
    "    lora_model_id=\"SeHee8546/kanana-1.5-8b-pakchanho-lora-v2\",\n",
    "    load_in_4bit=True,\n",
    ")\n",
    "\n",
    "# 2) ì„¸íŠ¸ë³„ analyst_text ì¬ìƒì„±\n",
    "game_title = \"2025 KBO ì¤€í”Œë ˆì´ì˜¤í”„ 4ì°¨ì „ ì‚¼ì„± vs SSG\"  # ê²½ê¸° ì •ë³´ëŠ” ìƒí™©ì— ë§ê²Œ ë°”ê¾¸ë©´ ë¨\n",
    "\n",
    "result_sets = generate_analyst_for_all_sets(\n",
    "    json_in_path=scoreboard_json_path,\n",
    "    json_out_path=json_llm_output_path,\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    game_title=game_title,\n",
    "    temperature=0.7,\n",
    "    top_p=0.9,\n",
    "    repetition_penalty=1.1,\n",
    "    no_repeat_ngram_size=3,\n",
    "    base_max_new_tokens=512,\n",
    ")\n",
    "\n",
    "print(f\"ì´ ì„¸íŠ¸ ìˆ˜: {len(result_sets)}\")\n",
    "print(f\"ì €ì¥ ì™„ë£Œ: {json_llm_output_path.resolve()}\")\n",
    "\n",
    "# 3) ìƒ˜í”Œ ëª‡ ê°œ í™•ì¸\n",
    "for row in result_sets[:5]:\n",
    "    print(\"=\" * 80)\n",
    "    print(\"set_id:\", row[\"set_id\"])\n",
    "    print(\"caster_text:\", row[\"caster_text\"])\n",
    "    print(\"analyst_text:\", row[\"analyst_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "518f027d-028e-4e37-bbc1-be2095a9dfc2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# JSON ê¸°ë°˜ TTS ì „ì²´ íŒŒì´í”„ë¼ì¸\n",
    "# ==========================================\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "from src.json_tts_pipeline import run_full_tts_pipeline_from_json\n",
    "\n",
    "\n",
    "# ì´ ì˜ìƒì— ëŒ€í•œ ì •ë³´ë“¤\n",
    "video_stem = local_video_path.stem\n",
    "\n",
    "# LLMì„ í†µê³¼í•œ ìµœì¢… ì„¸íŠ¸ JSON (ì§€ê¸ˆ ì˜¬ë ¤ì¤€ íŒŒì¼)\n",
    "# í˜„ì¬ëŠ” ì´ë¦„ì´ \"vocals_timeline_set_split_scoreboard_pakchanho (4).json\" ì´ë‹ˆê¹Œ\n",
    "# 1) íŒŒì¼ëª…ì„ ìœ„ ê·œì¹™ìœ¼ë¡œ ë°”ê¾¸ê±°ë‚˜\n",
    "# 2) ê·¸ëƒ¥ ì •í™•í•œ ì´ë¦„ì„ ì§ì ‘ Path ë¡œ ë„£ì–´ë„ ë©ë‹ˆë‹¤.\n",
    "# json_sets_path = DATA_DIR / \"llm_outputs\" / \"vocals_timeline_set_split_scoreboard_pakchanho (4).json\"\n",
    "\n",
    "# Fish-Speech API ì„¤ì •\n",
    "FISH_API_URL = \"http://127.0.0.1:8080/v1/tts\"\n",
    "\n",
    "CASTER_REF_WAVS = [DATA_DIR / \"tts_refs\" / \"caster_prompt_1.wav\"]\n",
    "ANALYST_REF_WAVS = [DATA_DIR / \"tts_refs\" / \"analyst_pakchanho_prompt_1.wav\"]\n",
    "\n",
    "print(f\"[TTS] JSON ê¸°ë°˜ TTS íŒŒì´í”„ë¼ì¸ ì‹œì‘\")\n",
    "print(f\"  JSON ì„¸íŠ¸ íŒŒì¼: {json_llm_output_path}\")\n",
    "print(f\"  ì›ë³¸ ì˜ìƒ: {local_video_path}\")\n",
    "print(f\"  ìºìŠ¤í„° ì°¸ì¡°: {CASTER_REF_WAVS}\")\n",
    "print(f\"  í•´ì„¤ ì°¸ì¡°: {ANALYST_REF_WAVS}\")\n",
    "\n",
    "try:\n",
    "    final_tts_wav, aligned_csv, tts_csv_with_paths = run_full_tts_pipeline_from_json(\n",
    "        json_sets_path=json_llm_output_path,\n",
    "        video_path=local_video_path,\n",
    "        caster_ref_wavs=CASTER_REF_WAVS,\n",
    "        analyst_ref_wavs=ANALYST_REF_WAVS,\n",
    "        fish_api_url=FISH_API_URL,\n",
    "        # ì•„ë˜ íŒŒë¼ë¯¸í„°ë“¤ì€ ê¸°ì¡´ ì…‹ì—… ê·¸ëŒ€ë¡œ ì‚¬ìš© (í•„ìš”í•˜ë©´ íŠœë‹ ê°€ëŠ¥)\n",
    "        min_text_chars=2,\n",
    "        merge_same_role=True,\n",
    "        merge_gap_thresh_sec=0.25,\n",
    "        merge_short_thresh_sec=1.0,\n",
    "        min_gap_sec=0.02,\n",
    "        caster_extra_ratio=0.2,\n",
    "        analyst_extra_ratio=2.0,\n",
    "        max_analyst_expand_sec=7.0,\n",
    "        analyst_priority_min_overlap_sec=0.5,\n",
    "        min_gap_ms=60,\n",
    "        tail_margin_ms=80,\n",
    "        caster_max_speedup=1.3,\n",
    "        analyst_max_speedup=1.8,\n",
    "    )\n",
    "\n",
    "    print(\"\\nâœ… JSON â†’ TTS â†’ ì •ë ¬ â†’ WSOLA ì „ì²´ ì™„ë£Œ!\")\n",
    "    print(f\"  - TTS CSV(with paths): {tts_csv_with_paths}\")\n",
    "    print(f\"  - ì •ë ¬ CSV: {aligned_csv}\")\n",
    "    print(f\"  - ìµœì¢… TTS íƒ€ì„ë¼ì¸ wav: {final_tts_wav}\\n\")\n",
    "\n",
    "    # í†µê³„ ì¶œë ¥ (ì„ íƒ)\n",
    "    tts_df = pd.read_csv(tts_csv_with_paths)\n",
    "    print(\"ğŸ“Š TTS í†µê³„:\")\n",
    "    print(f\"  - ì´ ë°œí™” ìˆ˜: {len(tts_df)}\")\n",
    "    print(f\"  - TTS ì„±ê³µ: {tts_df['tts_wav_path'].notna().sum()}ê°œ\")\n",
    "    print(f\"  - TTS ì‹¤íŒ¨: {tts_df['tts_wav_path'].isna().sum()}ê°œ\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\nâŒ JSON ê¸°ë°˜ TTS íŒŒì´í”„ë¼ì¸ ì‹¤íŒ¨: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "    raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "480757d1-335b-4dd0-9785-7c21002c0241",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# Cell 12: ìµœì¢… ì˜ìƒ ì¸ì½”ë”©\n",
    "# ==========================================\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "\n",
    "# â­ ì¶œë ¥ ë””ë ‰í† ë¦¬ ìˆ˜ì •\n",
    "OUTPUT_VIDEO_DIR = DATA_DIR / \"output_videos\"\n",
    "OUTPUT_VIDEO_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# â­ ê²½ë¡œ ëª…í™•í•˜ê²Œ ì •ì˜\n",
    "TTS_AUDIO_DIR = DATA_DIR / \"tts_audio\" / video_stem\n",
    "AUDIO_SEPARATOR_DIR = DATA_DIR / \"audio_separator\"\n",
    "\n",
    "# TTS íƒ€ì„ë¼ì¸ wav (ìµœì¢… ìƒì„±ëœ TTS ìŒì„±)\n",
    "final_tts_wav = TTS_AUDIO_DIR / f\"{video_stem}.tts_timeline.wav\"\n",
    "\n",
    "# Audio Separatorì—ì„œ ë¶„ë¦¬í•œ ë°°ê²½ìŒ\n",
    "no_vocals_path = AUDIO_SEPARATOR_DIR / \"no_vocals.wav\"\n",
    "\n",
    "def get_duration(file_path: Path) -> float:\n",
    "    \"\"\"íŒŒì¼ì˜ ê¸¸ì´ë¥¼ ì´ˆ ë‹¨ìœ„ë¡œ ë°˜í™˜\"\"\"\n",
    "    cmd = [\n",
    "        'ffprobe', '-v', 'error',\n",
    "        '-show_entries', 'format=duration',\n",
    "        '-of', 'default=noprint_wrappers=1:nokey=1',\n",
    "        str(file_path)\n",
    "    ]\n",
    "    result = subprocess.run(cmd, capture_output=True, encoding='utf-8', errors='replace', check=True)\n",
    "    return float(result.stdout.strip())\n",
    "\n",
    "def merge_audio_and_encode_video(\n",
    "    original_video_path: Path,\n",
    "    tts_vocals_path: Path,\n",
    "    bg_no_vocals_path: Path,\n",
    "    output_video_path: Path,\n",
    "    tts_volume: float = 1.0,\n",
    "    bg_volume: float = 0.7,\n",
    ") -> Path:\n",
    "    \"\"\"\n",
    "    1) TTS vocals + ë°°ê²½ìŒ(no_vocals) ë¯¹ì‹±\n",
    "    2) ì›ë³¸ ë¹„ë””ì˜¤ì™€ í•©ì³ì„œ ìµœì¢… ì˜ìƒ ìƒì„±\n",
    "    \"\"\"\n",
    "    output_video_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ ë¨¼ì € í™•ì¸\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"ğŸ“ íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    files_to_check = {\n",
    "        \"ì›ë³¸ ë¹„ë””ì˜¤\": original_video_path,\n",
    "        \"TTS ì˜¤ë””ì˜¤\": tts_vocals_path,\n",
    "        \"ë°°ê²½ìŒ\": bg_no_vocals_path,\n",
    "    }\n",
    "    \n",
    "    for name, path in files_to_check.items():\n",
    "        if path.exists():\n",
    "            size_mb = path.stat().st_size / (1024**2)\n",
    "            print(f\"âœ… {name}: {path.name} ({size_mb:.2f} MB)\")\n",
    "        else:\n",
    "            print(f\"âŒ {name}: {path}\")\n",
    "            raise FileNotFoundError(f\"{name} íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {path}\")\n",
    "    \n",
    "    print(\"=\" * 80 + \"\\n\")\n",
    "    \n",
    "    # íŒŒì¼ ê¸¸ì´ í™•ì¸\n",
    "    try:\n",
    "        video_duration = get_duration(original_video_path)\n",
    "        tts_duration = get_duration(tts_vocals_path)\n",
    "        bg_duration = get_duration(bg_no_vocals_path)\n",
    "        \n",
    "        print(f\"[INFO] ğŸ“¹ ë¹„ë””ì˜¤ ê¸¸ì´: {video_duration:.2f}ì´ˆ ({int(video_duration//60)}ë¶„ {int(video_duration%60)}ì´ˆ)\")\n",
    "        print(f\"[INFO] ğŸ¤ TTS ì˜¤ë””ì˜¤ ê¸¸ì´: {tts_duration:.2f}ì´ˆ ({int(tts_duration//60)}ë¶„ {int(tts_duration%60)}ì´ˆ)\")\n",
    "        print(f\"[INFO] ğŸµ ë°°ê²½ìŒ ê¸¸ì´: {bg_duration:.2f}ì´ˆ ({int(bg_duration//60)}ë¶„ {int(bg_duration%60)}ì´ˆ)\")\n",
    "        \n",
    "        # ê¸¸ì´ ì°¨ì´ê°€ í¬ë©´ ê²½ê³ \n",
    "        if abs(tts_duration - bg_duration) > 5.0:\n",
    "            print(f\"[WARNING] âš ï¸ TTSì™€ ë°°ê²½ìŒ ê¸¸ì´ ì°¨ì´: {abs(tts_duration - bg_duration):.2f}ì´ˆ\")\n",
    "        if abs(video_duration - tts_duration) > 5.0:\n",
    "            print(f\"[WARNING] âš ï¸ ë¹„ë””ì˜¤ì™€ TTS ê¸¸ì´ ì°¨ì´: {abs(video_duration - tts_duration):.2f}ì´ˆ\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"[WARNING] íŒŒì¼ ê¸¸ì´ í™•ì¸ ì‹¤íŒ¨: {e}\")\n",
    "        print(\"[INFO] ê¸¸ì´ í™•ì¸ ì—†ì´ ì§„í–‰í•©ë‹ˆë‹¤...\")\n",
    "    \n",
    "    print()\n",
    "    \n",
    "    # ë” ì•ˆì „í•œ FFmpeg ëª…ë ¹ì–´ (2ë‹¨ê³„ ì²˜ë¦¬)\n",
    "    # Step 1: ì˜¤ë””ì˜¤ ë¯¹ì‹±\n",
    "    mixed_audio_path = output_video_path.parent / f\"{output_video_path.stem}_mixed_audio.wav\"\n",
    "    \n",
    "    audio_cmd = [\n",
    "        'ffmpeg', '-y',\n",
    "        '-i', str(tts_vocals_path),\n",
    "        '-i', str(bg_no_vocals_path),\n",
    "        '-filter_complex',\n",
    "        f'[0:a]volume={tts_volume}[a1];'\n",
    "        f'[1:a]volume={bg_volume}[a2];'\n",
    "        f'[a1][a2]amix=inputs=2:duration=longest:normalize=0[aout]',\n",
    "        '-map', '[aout]',\n",
    "        '-ar', '44100',  # ìƒ˜í”Œë ˆì´íŠ¸ ê³ ì •\n",
    "        '-ac', '2',       # ìŠ¤í…Œë ˆì˜¤\n",
    "        str(mixed_audio_path)\n",
    "    ]\n",
    "    \n",
    "    print(\"[STEP 1] ğŸµ ì˜¤ë””ì˜¤ ë¯¹ì‹± ì¤‘...\")\n",
    "    \n",
    "    result = subprocess.run(audio_cmd, capture_output=True, encoding='utf-8', errors='replace')\n",
    "    \n",
    "    if result.returncode != 0:\n",
    "        print(f\"\\nâŒ ì˜¤ë””ì˜¤ ë¯¹ì‹± ì‹¤íŒ¨!\")\n",
    "        print(f\"Return code: {result.returncode}\")\n",
    "        print(f\"\\nStderr:\\n{result.stderr}\")\n",
    "        raise subprocess.CalledProcessError(result.returncode, audio_cmd, result.stdout, result.stderr)\n",
    "    \n",
    "    print(f\"[STEP 1] âœ… ì˜¤ë””ì˜¤ ë¯¹ì‹± ì™„ë£Œ!\")\n",
    "    \n",
    "    # Step 2: ë¹„ë””ì˜¤ì™€ ì˜¤ë””ì˜¤ ê²°í•©\n",
    "    video_cmd = [\n",
    "        'ffmpeg', '-y',\n",
    "        '-i', str(original_video_path),\n",
    "        '-i', str(mixed_audio_path),\n",
    "        '-map', '0:v:0',\n",
    "        '-map', '1:a:0',\n",
    "        '-c:v', 'libx264',\n",
    "        '-preset', 'medium',\n",
    "        '-crf', '23',\n",
    "        '-c:a', 'aac',\n",
    "        '-b:a', '192k',\n",
    "        '-shortest',\n",
    "        str(output_video_path)\n",
    "    ]\n",
    "    \n",
    "    print(\"[STEP 2] ğŸ¬ ë¹„ë””ì˜¤ ì¸ì½”ë”© ì¤‘...\")\n",
    "    \n",
    "    result = subprocess.run(video_cmd, capture_output=True, encoding='utf-8', errors='replace')\n",
    "    \n",
    "    if result.returncode != 0:\n",
    "        print(f\"\\nâŒ ë¹„ë””ì˜¤ ì¸ì½”ë”© ì‹¤íŒ¨!\")\n",
    "        print(f\"Return code: {result.returncode}\")\n",
    "        print(f\"\\nStderr:\\n{result.stderr}\")\n",
    "        raise subprocess.CalledProcessError(result.returncode, video_cmd, result.stdout, result.stderr)\n",
    "    \n",
    "    # ì„ì‹œ ì˜¤ë””ì˜¤ íŒŒì¼ ì‚­ì œ\n",
    "    try:\n",
    "        mixed_audio_path.unlink()\n",
    "        print(f\"[CLEANUP] ğŸ—‘ï¸  ì„ì‹œ íŒŒì¼ ì‚­ì œ ì™„ë£Œ\")\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    print(f\"[STEP 2] âœ… ë¹„ë””ì˜¤ ì¸ì½”ë”© ì™„ë£Œ!\")\n",
    "    return output_video_path\n",
    "\n",
    "# ìµœì¢… ì¶œë ¥ ì˜ìƒ ê²½ë¡œ\n",
    "final_video_path = OUTPUT_VIDEO_DIR / f\"{video_stem}.final.mp4\"\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"ğŸ¬ ìµœì¢… ì˜ìƒ ìƒì„± ì‹œì‘\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"  ğŸ“¹ ì›ë³¸ ë¹„ë””ì˜¤: {local_video_path.name}\")\n",
    "print(f\"  ğŸ¤ TTS ìŒì„±: {final_tts_wav.name}\")\n",
    "print(f\"  ğŸµ ë°°ê²½ìŒ: {no_vocals_path.name}\")\n",
    "print(f\"  ğŸ’¾ ì¶œë ¥: {final_video_path.name}\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "try:\n",
    "    final_video = merge_audio_and_encode_video(\n",
    "        original_video_path=local_video_path,\n",
    "        tts_vocals_path=final_tts_wav,\n",
    "        bg_no_vocals_path=no_vocals_path,\n",
    "        output_video_path=final_video_path,\n",
    "        tts_volume=1.0,\n",
    "        bg_volume=0.7,\n",
    "    )\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"ğŸ‰ ì „ì²´ íŒŒì´í”„ë¼ì¸ ì™„ë£Œ!\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"âœ… ìµœì¢… ì˜ìƒ: {final_video}\")\n",
    "    print(f\"ğŸ“¦ íŒŒì¼ í¬ê¸°: {final_video.stat().st_size / (1024**2):.2f} MB\")\n",
    "    \n",
    "    # ìµœì¢… ì˜ìƒ ê¸¸ì´ í™•ì¸\n",
    "    try:\n",
    "        final_duration = get_duration(final_video)\n",
    "        print(f\"â±ï¸  ì˜ìƒ ê¸¸ì´: {final_duration:.2f}ì´ˆ ({int(final_duration//60)}ë¶„ {int(final_duration%60)}ì´ˆ)\")\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    print(\"=\"*80 + \"\\n\")\n",
    "    \n",
    "except subprocess.CalledProcessError as e:\n",
    "    print(f\"\\nâŒ FFmpeg ì¸ì½”ë”© ì‹¤íŒ¨!\")\n",
    "    print(f\"ì—ëŸ¬ ì½”ë“œ: {e.returncode}\")\n",
    "    if e.stderr:\n",
    "        print(f\"\\nìƒì„¸ ì—ëŸ¬ ë©”ì‹œì§€:\")\n",
    "        print(\"=\" * 80)\n",
    "        print(e.stderr)\n",
    "        print(\"=\" * 80)\n",
    "    raise\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\nâŒ ìµœì¢… ì¸ì½”ë”© ì‹¤íŒ¨: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "    raise"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "skn17_final_env (Runpod)",
   "language": "python",
   "name": "skn17_final_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
