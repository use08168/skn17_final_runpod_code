# src/audio_concat_test.py

from __future__ import annotations

from pathlib import Path
from typing import Optional

import pandas as pd
from pydub import AudioSegment
import subprocess


def _find_tts_wav_for_utt(
    tts_audio_dir: Path,
    utt_id: str,
    role: Optional[str] = None,
) -> Optional[Path]:
    """
    utterance_id ì— ëŒ€ì‘í•˜ëŠ” wav íŒŒì¼ì„ ì°¾ëŠ”ë‹¤.

    ìš°ì„ ìˆœìœ„:
    1) {tts_audio_dir}/{utt_id}.wav
    2) {tts_audio_dir}/{role}/{utt_id}.wav  (role=caster/analyst ë“±)
    """
    cand = tts_audio_dir / f"{utt_id}.wav"
    if cand.exists():
        return cand

    if role:
        role = str(role).strip().lower()
        cand2 = tts_audio_dir / role / f"{utt_id}.wav"
        if cand2.exists():
            return cand2

    return None


def _get_video_duration_ms(input_video_path: Path) -> int:
    """
    ë¹„ë””ì˜¤ íŒŒì¼ì—ì„œ ì˜¤ë””ì˜¤ íŠ¸ë™ì„ ì½ì–´ì„œ ì „ì²´ ê¸¸ì´(ms)ë¥¼ êµ¬í•œë‹¤.
    (ffmpeg + pydub ì‚¬ìš©)
    """
    seg = AudioSegment.from_file(str(input_video_path))
    return len(seg)


def build_sequential_tts_audio(
    llm_csv_path: Path | str,
    tts_audio_dir: Path | str,
    out_wav_path: Path | str,
    gap_ms_between_roles: int = 0,
    role_gain_db: Optional[dict[str, float]] = None,
) -> Path:
    """
    íƒ€ì„ìŠ¤íƒ¬í”„ë¥¼ ë¬´ì‹œí•˜ê³ , CSV ì— ìˆëŠ” utterance ìˆœì„œëŒ€ë¡œ
    TTS wavë“¤ì„ ì­‰ ì´ì–´ë¶™ì—¬ í•˜ë‚˜ì˜ ì˜¤ë””ì˜¤ë¥¼ ë§Œë“ ë‹¤.

    - llm_csv_path: clip.tts_phrases.llm_kanana.csv ë“±
      (í•„ìˆ˜ ì»¬ëŸ¼: utterance_id, role)
      start_sec ì´ ìˆìœ¼ë©´ ê·¸ ìˆœì„œëŒ€ë¡œ ì •ë ¬, ì—†ìœ¼ë©´ CSV ìˆœì„œë¥¼ ê·¸ëŒ€ë¡œ ì‚¬ìš©
    - tts_audio_dir: ê°œë³„ TTS wav ê°€ ìˆëŠ” ë””ë ‰í† ë¦¬
      (ì˜ˆ: data/tts_audio/clip)
    - out_wav_path: ì´ì–´ë¶™ì¸ ê²°ê³¼ wav ê²½ë¡œ
    - gap_ms_between_roles:
      ìºìŠ¤í„°/í•´ì„¤ìœ„ì› ë“± role ì´ ë°”ë€” ë•Œ ì‚½ì…í•  ê³µë°±(ms).
      ì˜ˆ: 150 â†’ ìºìŠ¤í„°â†’í•´ì„¤ìœ„ì› ì „í™˜ë§ˆë‹¤ 0.15ì´ˆ ì¹¨ë¬µ
    - role_gain_db:
      ì—­í• ë³„ ë³¼ë¥¨ ì¡°ì ˆ(dB). ì˜ˆ:
        {"caster": +1.5, "analyst": -1.0}
      role ì»¬ëŸ¼ì„ ì†Œë¬¸ìë¡œ normalize í•´ì„œ lookup í•œë‹¤.
    """
    llm_csv_path = Path(llm_csv_path)
    tts_audio_dir = Path(tts_audio_dir)
    out_wav_path = Path(out_wav_path)

    df = pd.read_csv(llm_csv_path)
    df.columns = [c.replace("\ufeff", "").strip() for c in df.columns]

    if "utterance_id" not in df.columns:
        raise ValueError("[CONCAT] CSV ì— utterance_id ì»¬ëŸ¼ì´ í•„ìš”í•©ë‹ˆë‹¤.")

    # ì •ë ¬ ê¸°ì¤€: start_sec ì´ ìˆìœ¼ë©´ ê·¸ê±¸ë¡œ, ì•„ë‹ˆë©´ ì…ë ¥ ê·¸ëŒ€ë¡œ
    if "start_sec" in df.columns:
        df = df.copy()
        df["start_sec"] = pd.to_numeric(df["start_sec"], errors="coerce")
        df = df.sort_values("start_sec")

    segments: list[AudioSegment] = []
    prev_role_norm: Optional[str] = None

    # role_gain_db í‚¤ëŠ” ì†Œë¬¸ì ê¸°ì¤€ìœ¼ë¡œ ë§ì¶°ë‘”ë‹¤
    if role_gain_db is not None:
        role_gain_db = {str(k).strip().lower(): float(v) for k, v in role_gain_db.items()}

    for row in df.itertuples(index=False):
        utt_id = str(getattr(row, "utterance_id"))
        role_raw = getattr(row, "role", "")
        role_norm = str(role_raw).strip().lower()

        wav_path = _find_tts_wav_for_utt(tts_audio_dir, utt_id, role=role_norm)
        if wav_path is None:
            print(f"[CONCAT] WARN: wav not found for utt={utt_id}, role={role_raw}")
            continue

        # ğŸ”¹ ìºìŠ¤í„° â†” í•´ì„¤ìœ„ì› ë“± í™”ìê°€ ë°”ë€ŒëŠ” ìˆœê°„ì—” ì‚´ì§ ê³µë°± ì‚½ì…
        if (
            prev_role_norm is not None
            and role_norm
            and role_norm != prev_role_norm
            and gap_ms_between_roles > 0
        ):
            gap = AudioSegment.silent(duration=gap_ms_between_roles)
            segments.append(gap)
            print(
                f"[CONCAT] insert gap {gap_ms_between_roles}ms "
                f"between {prev_role_norm} -> {role_norm}"
            )

        seg = AudioSegment.from_file(wav_path)

        # ğŸ”¹ ì—­í• ë³„ ë³¼ë¥¨ ì¡°ì ˆ (dB ë‹¨ìœ„)
        gain_db = 0.0
        if role_gain_db is not None:
            gain_db = float(role_gain_db.get(role_norm, 0.0))
        if gain_db != 0.0:
            seg = seg + gain_db  # pydub: +dB / -dB
            print(
                f"[CONCAT] apply gain {gain_db:+.2f} dB "
                f"for role={role_raw} (utt={utt_id})"
            )

        segments.append(seg)
        print(
            f"[CONCAT] append utt={utt_id} role={role_raw} "
            f"dur={len(seg)/1000:.2f}s"
        )

        prev_role_norm = role_norm

    if not segments:
        raise ValueError("[CONCAT] ì´ì–´ë¶™ì¼ TTS ì˜¤ë””ì˜¤ê°€ ì—†ìŠµë‹ˆë‹¤.")

    full = segments[0]
    for seg in segments[1:]:
        full += seg

    out_wav_path.parent.mkdir(parents=True, exist_ok=True)
    full.export(out_wav_path, format="wav")
    print("[CONCAT] saved full TTS wav:", out_wav_path)
    return out_wav_path


def cut_audio_to_video_length(
    audio_path: Path | str,
    input_video_path: Path | str,
    out_wav_path: Optional[Path | str] = None,
) -> Path:
    """
    audio_path ì˜ ê¸¸ì´ê°€ ë¹„ë””ì˜¤ ê¸¸ì´ë³´ë‹¤ ê¸¸ë©´,
    ë¹„ë””ì˜¤ ê¸¸ì´ì— ë§ì¶° ì˜ë¼ë‚¸ ìƒˆ wav ë¥¼ ìƒì„±í•œë‹¤.

    - ë¹„ë””ì˜¤ ê¸¸ì´ë³´ë‹¤ ì§§ìœ¼ë©´ ê·¸ëŒ€ë¡œ ë‘”ë‹¤.
    """
    audio_path = Path(audio_path)
    input_video_path = Path(input_video_path)
    if out_wav_path is None:
        out_wav_path = audio_path
    out_wav_path = Path(out_wav_path)

    video_ms = _get_video_duration_ms(input_video_path)
    audio = AudioSegment.from_file(str(audio_path))
    audio_ms = len(audio)

    print(
        f"[CUT] video_ms={video_ms}ms ({video_ms/1000:.2f}s), "
        f"audio_ms={audio_ms}ms ({audio_ms/1000:.2f}s)"
    )

    if audio_ms <= video_ms:
        if out_wav_path != audio_path:
            audio.export(out_wav_path, format="wav")
        print("[CUT] audio <= video, ê·¸ëŒ€ë¡œ ì‚¬ìš©:", out_wav_path)
        return out_wav_path

    trimmed = audio[:video_ms]
    out_wav_path.parent.mkdir(parents=True, exist_ok=True)
    trimmed.export(out_wav_path, format="wav")
    print("[CUT] trimmed audio to video length:", out_wav_path)
    return out_wav_path


def mux_tts_audio_to_video_concat(
    input_video_path: Path | str,
    tts_audio_path: Path | str,
    out_video_path: Path | str,
    mute_original: bool = True,
) -> Path:
    """
    ffmpeg ë¥¼ ì´ìš©í•´:

    - ì›ë³¸ ë¹„ë””ì˜¤ì˜ ì˜ìƒì„ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•˜ê³ 
    - ì˜¤ë””ì˜¤ëŠ” TTS wav ë¥¼ ë¶™ì¸ë‹¤.
      - mute_original=True  â†’ ì›ë³¸ ìŒì†Œê±° + TTSë§Œ ì‚¬ìš©
      - mute_original=False â†’ ì›ë³¸ + TTSë¥¼ amix ë¡œ ì„ê¸°
    """
    input_video_path = Path(input_video_path)
    tts_audio_path = Path(tts_audio_path)
    out_video_path = Path(out_video_path)

    out_video_path.parent.mkdir(parents=True, exist_ok=True)

    if mute_original:
        cmd = [
            "ffmpeg",
            "-y",
            "-i",
            str(input_video_path),
            "-i",
            str(tts_audio_path),
            "-map",
            "0:v:0",
            "-map",
            "1:a:0",
            "-c:v",
            "copy",
            "-c:a",
            "aac",
            "-shortest",
            str(out_video_path),
        ]
    else:
        cmd = [
            "ffmpeg",
            "-y",
            "-i",
            str(input_video_path),
            "-i",
            str(tts_audio_path),
            "-filter_complex",
            "[0:a][1:a]amix=inputs=2:duration=longest:dropout_transition=0[aout]",
            "-map",
            "0:v:0",
            "-map",
            "[aout]",
            "-c:v",
            "copy",
            "-c:a",
            "aac",
            "-shortest",
            str(out_video_path),
        ]

    print("[MUX(CONCAT)] CMD:", " ".join(cmd))
    subprocess.run(cmd, check=True)
    print("[MUX(CONCAT)] saved video:", out_video_path)
    return out_video_path


def build_sequential_tts_video(
    llm_csv_path: Path | str,
    tts_audio_dir: Path | str,
    input_video_path: Path | str,
    out_wav_path: Path | str,
    out_video_path: Path | str,
    mute_original: bool = True,
    gap_ms_between_roles: int = 0,
    role_gain_db: Optional[dict[str, float]] = None,
) -> Path:
    """
    í¸ì˜ë¥¼ ìœ„í•œ one-shot í•¨ìˆ˜:

    1) CSV ìˆœì„œëŒ€ë¡œ TTS wav ë“¤ì„ ì´ì–´ë¶™ì—¬ í•˜ë‚˜ì˜ ì˜¤ë””ì˜¤ ìƒì„±
       - role ì´ ë°”ë€” ë•Œë§ˆë‹¤ gap_ms_between_roles ë§Œí¼ ì¹¨ë¬µ ì‚½ì…
       - role_gain_db ë¡œ ì—­í• ë³„ ë³¼ë¥¨ ì¡°ì ˆ
    2) ê·¸ ì˜¤ë””ì˜¤ê°€ ì˜ìƒë³´ë‹¤ ê¸¸ë©´, ì˜ìƒ ê¸¸ì´ì— ë§ì¶° ì˜ë¼ëƒ„
    3) ì˜ë¼ë‚¸ ì˜¤ë””ì˜¤ë¥¼ ì˜ìƒì— ë¶™ì—¬ì„œ ìµœì¢… mp4 ìƒì„±
    """
    llm_csv_path = Path(llm_csv_path)
    tts_audio_dir = Path(tts_audio_dir)
    input_video_path = Path(input_video_path)
    out_wav_path = Path(out_wav_path)
    out_video_path = Path(out_video_path)

    full_wav = build_sequential_tts_audio(
        llm_csv_path=llm_csv_path,
        tts_audio_dir=tts_audio_dir,
        out_wav_path=out_wav_path,
        gap_ms_between_roles=gap_ms_between_roles,
        role_gain_db=role_gain_db,
    )

    trimmed_wav = cut_audio_to_video_length(
        audio_path=full_wav,
        input_video_path=input_video_path,
        out_wav_path=out_wav_path,  # ê°™ì€ ê²½ë¡œì— ë®ì–´ì“°ê¸°
    )

    final_video = mux_tts_audio_to_video_concat(
        input_video_path=input_video_path,
        tts_audio_path=trimmed_wav,
        out_video_path=out_video_path,
        mute_original=mute_original,
    )
    return final_video
