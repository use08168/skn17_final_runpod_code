# src/llm_preprocess_align.py

from __future__ import annotations

from pathlib import Path
from typing import Optional, Iterable, List

import numpy as np
import pandas as pd

# ì—­í•  ì„¸íŠ¸ (í•„ìš”í•˜ë©´ í”„ë¡œì íŠ¸ì— ë§ê²Œ ìˆ˜ì •)
DEFAULT_CASTER_ROLES: set[str] = {"caster", "A"}
DEFAULT_ANALYST_ROLES: set[str] = {"analyst", "B", "C"}


def _choose_text_for_len(row) -> str:
    """
    ê¸¸ì´ íŒë‹¨ìš© í…ìŠ¤íŠ¸ ì„ íƒ:
    - ìºìŠ¤í„°: orig_text
    - í•´ì„¤:   llm_text
    """
    role_raw = str(getattr(row, "role", "")).strip().lower()
    if role_raw == "caster":
        raw = getattr(row, "orig_text", "")
    else:
        raw = getattr(row, "llm_text", "")

    if pd.isna(raw):
        return ""
    s = str(raw).strip()
    if not s or s.lower() == "nan":
        return ""
    return s


def _estimate_slot_duration_from_text(
    row,
    *,
    role_col: str,
    caster_roles: set[str],
    analyst_roles: set[str],
    caster_chars_per_sec: float,
    analyst_chars_per_sec: float,
    dur_margin_ratio: float,
) -> float:
    """
    í…ìŠ¤íŠ¸ ê¸¸ì´(ë°œí™”ëŸ‰) ê¸°ë°˜ìœ¼ë¡œ "ì´ ì •ë„ëŠ” ì¤˜ì•¼ ë§í•  ìˆ˜ ìˆë‹¤" í•˜ëŠ”
    ìŠ¬ë¡¯ ê¸¸ì´ë¥¼ ì¶”ì •í•œë‹¤.

    - ê³µë°± ì œê±°í•œ ê¸€ì ìˆ˜ / (ì—­í• ë³„ ê¸€ì/ì´ˆ) * (1 + margin) êµ¬ì¡°
    """
    txt = _choose_text_for_len(row)
    # ê³µë°± ì œê±° í›„ ê¸€ì ìˆ˜
    n_chars = len("".join(txt.split()))
    if n_chars <= 0:
        return 0.0

    role_raw = str(getattr(row, role_col, "")).strip().lower()

    if role_raw in caster_roles:
        cps = caster_chars_per_sec
    elif role_raw in analyst_roles:
        cps = analyst_chars_per_sec
    else:
        cps = analyst_chars_per_sec  # ê¸°ë³¸ í•´ì„¤ ì†ë„ë¡œ

    if cps <= 0:
        return 0.0

    base = n_chars / cps  # ì´ˆ ë‹¨ìœ„
    return base * (1.0 + dur_margin_ratio)


def _apply_analyst_priority_pre(
    df: pd.DataFrame,
    *,
    start_col: str,
    end_col: str,
    role_col: str,
    caster_roles: set[str],
    analyst_roles: set[str],
    min_overlap_sec: float,
) -> pd.DataFrame:
    """
    (ì •ë ¬/ìŠ¬ë¡¯ ì¬ê³„ì‚° ì „) ì›ë˜ start/end ê¸°ì¤€ìœ¼ë¡œ
    í•´ì„¤ êµ¬ê°„ê³¼ ê²¹ì¹˜ëŠ” ìºìŠ¤í„° êµ¬ê°„ì„ ì œê±°í•œë‹¤.

    - min_overlap_sec <= 0: "ì¡°ê¸ˆì´ë¼ë„" ê²¹ì¹˜ë©´ ìºìŠ¤í„° ë“œë¡­
    - min_overlap_sec > 0:  ê²¹ì¹˜ëŠ” ê¸¸ì´ê°€ ì´ ê°’ ì´ìƒì¼ ë•Œë§Œ ìºìŠ¤í„° ë“œë¡­
    """
    if min_overlap_sec is None:
        return df

    if min_overlap_sec < 0:
        min_overlap_sec = 0.0

    roles = df[role_col].astype(str).str.strip().str.lower().to_numpy()
    starts = df[start_col].to_numpy(float)
    ends = df[end_col].to_numpy(float)

    caster_roles = {r.lower() for r in caster_roles}
    analyst_roles = {r.lower() for r in analyst_roles}

    is_caster = np.isin(roles, list(caster_roles))
    is_analyst = np.isin(roles, list(analyst_roles))

    drop_mask = np.zeros(len(df), dtype=bool)

    for i in range(len(df)):
        if not is_analyst[i]:
            continue

        a_start = starts[i]
        a_end = ends[i]

        # ëª¨ë“  êµ¬ê°„ê³¼ì˜ ê²¹ì¹˜ëŠ” ê¸¸ì´
        overlap_len = np.minimum(ends, a_end) - np.maximum(starts, a_start)

        if min_overlap_sec <= 0:
            conflict = overlap_len > 0
        else:
            conflict = overlap_len >= min_overlap_sec

        conflict &= is_caster
        conflict[i] = False  # ìê¸° ìì‹ ì€ ì œì™¸

        if np.any(conflict):
            drop_mask |= conflict

    if drop_mask.any():
        before = len(df)
        df = df.loc[~drop_mask].copy()
        df = df.sort_values(start_col).reset_index(drop=True)
        print(f"[LLM_PRE_ALIGN] analyst priority drop casters: {before} -> {len(df)}")
    else:
        print("[LLM_PRE_ALIGN] analyst priority: no caster rows dropped")

    return df


def preprocess_and_align_llm_csv(
    llm_csv_path: Path | str,
    out_csv_path: Optional[Path | str] = None,
    *,
    # ì‹œê°„/ì»¬ëŸ¼ ì´ë¦„
    start_col: str = "start_sec",
    end_col: str = "end_sec",
    role_col: str = "role",
    uttid_col: str = "utterance_id",
    caster_roles: Iterable[str] = DEFAULT_CASTER_ROLES,
    analyst_roles: Iterable[str] = DEFAULT_ANALYST_ROLES,
    # ===== í…ìŠ¤íŠ¸/êµ¬ê°„ ì „ì²˜ë¦¬ íŒŒë¼ë¯¸í„° =====
    min_text_chars: int = 2,
    # ê°™ì€ í™”ìê°€ ì•„ì£¼ ì§§ê²Œ ìª¼ê°œì§„ êµ¬ê°„ì„ merge í•  ê¸°ì¤€
    merge_same_role: bool = True,
    merge_gap_thresh_sec: float = 0.25,   # ì•/ë’¤ êµ¬ê°„ ì‚¬ì´ ê°„ê²©ì´ ì´ ì´í•˜ë©´ í•©ì¹˜ê¸°
    merge_short_thresh_sec: float = 1.0,  # ë‘˜ ì¤‘ í•˜ë‚˜ë¼ë„ ì´ë³´ë‹¤ ì§§ìœ¼ë©´ í•©ì¹˜ê¸° í›„ë³´
    # ===== ìŠ¬ë¡¯ ê¸¸ì´ íŠœë‹ íŒŒë¼ë¯¸í„° =====
    min_gap_sec: float = 0.02,           # ë°œí™”ë“¤ ì‚¬ì´ ìµœì†Œ ê°„ê²©
    caster_extra_ratio: float = 0.0,     # ìºìŠ¤í„° slot ëŠ˜ë¦¬ëŠ” ë¹„ìœ¨ (0.2 â†’ 1.2ë°°)
    analyst_extra_ratio: float = 0.5,    # í•´ì„¤ slot ëŠ˜ë¦¬ëŠ” ë¹„ìœ¨ (2.0 â†’ 3ë°°)
    max_analyst_expand_sec: float = 7.0, # í•´ì„¤ 1ì¤„ë‹¹ ìµœëŒ€ +7ì´ˆê¹Œì§€ë§Œ í™•ì¥
    # ===== í…ìŠ¤íŠ¸ ê¸¸ì´ ê¸°ë°˜ duration ì¶”ì • íŒŒë¼ë¯¸í„° =====
    caster_chars_per_sec: float = 9.0,   # ìºìŠ¤í„° í‰ê·  9ê¸€ì/ì´ˆ ì •ë„
    analyst_chars_per_sec: float = 7.0,  # í•´ì„¤ í‰ê·  7ê¸€ì/ì´ˆ ì •ë„
    dur_margin_ratio: float = 0.2,       # ì˜ˆì¸¡ ì‹œê°„ì— 20% ì—¬ìœ 
    # ì „ì—­ ìŠ¬ë¡¯ ìŠ¤ì¼€ì¼
    global_slot_scale: float = 1.0,
    # ===== í•´ì„¤ ìš°ì„  ì „ëµ (ì „ì²˜ë¦¬ ë‹¨ê³„ì—ì„œ ìºìŠ¤í„° drop) =====
    analyst_priority_min_overlap_sec: Optional[float] = None,
) -> Path:
    """
    1) LLM CSVë¥¼ ì „ì²˜ë¦¬ (ì´ìƒí•˜ê²Œ ì§§ê²Œ ìª¼ê°œì§„ êµ¬ê°„ merge ë“±)
    2) (ì„ íƒ) í•´ì„¤ êµ¬ê°„ê³¼ ê²¹ì¹˜ëŠ” ìºìŠ¤í„° êµ¬ê°„ drop
    3) start_sec / end_secë¥¼ ì—­í• ë³„ ìŠ¬ë¡¯ ì •ì±…ì— ë§ê²Œ ì¬ê³„ì‚°
       - ì›ë˜ STT duration
       - í…ìŠ¤íŠ¸ ê¸¸ì´ ê¸°ë°˜ ì˜ˆì¸¡ duration
       - extra_ratio ê¸°ë°˜ duration
       ì´ ì…‹ì„ ì„ì–´ì„œ, "ë°œí™”ëŸ‰ì— ë§ëŠ” ìŠ¬ë¡¯"ì„ ë§Œë“ ë‹¤.

    ì¶œë ¥ CSV:
      - ì›ë³¸ ì£¼ìš” ì»¬ëŸ¼ ìœ ì§€ (utterance_id, role, orig_text, llm_text, start_sec, end_sec, ...)
      - orig_start_sec, orig_end_sec ëŠ” ë‚´ë¶€ ê³„ì‚°ìš©ìœ¼ë¡œë§Œ ì‚¬ìš©í•˜ê³ ,
        ìµœì¢… CSVì—ëŠ” í¬í•¨ë˜ì§€ ì•ŠëŠ”ë‹¤.
    """
    llm_csv_path = Path(llm_csv_path)

    df = pd.read_csv(llm_csv_path)
    df.columns = [c.replace("\ufeff", "").strip() for c in df.columns]

    required = {uttid_col, role_col, start_col, end_col}
    if not required.issubset(df.columns):
        raise ValueError(
            f"[LLM_PRE_ALIGN] CSVì— {required} ì»¬ëŸ¼ì´ í•„ìš”í•©ë‹ˆë‹¤. "
            f"í˜„ì¬ ì»¬ëŸ¼: {df.columns.tolist()}"
        )

    caster_roles = {r.lower() for r in caster_roles}
    analyst_roles = {r.lower() for r in analyst_roles}

    # ì‹œê°„ ì •ë¦¬
    df = df.dropna(subset=[start_col, end_col]).copy()
    df[start_col] = df[start_col].astype(float)
    df[end_col] = df[end_col].astype(float)
    df = df.sort_values(start_col).reset_index(drop=True)

    if df.empty:
        raise ValueError("[LLM_PRE_ALIGN] CSV ì— ìœ íš¨í•œ êµ¬ê°„ì´ ì—†ìŠµë‹ˆë‹¤.")

    # ì›ë³¸ start/end ë°±ì—… (ë‚´ë¶€ ê³„ì‚°ìš©)
    df["orig_start_sec"] = df[start_col]
    df["orig_end_sec"] = df[end_col]

    # ====== 1ë‹¨ê³„: í…ìŠ¤íŠ¸ ê¸°ë°˜ ì „ì²˜ë¦¬ (ë¹ˆ ì¤„/ë§¤ìš° ì§§ì€ ì¤„ ì œê±°) ======
    keep_mask: List[bool] = []
    for row in df.itertuples(index=False):
        txt = _choose_text_for_len(row)
        keep = len(txt) >= min_text_chars
        keep_mask.append(keep)

    df = df[keep_mask].reset_index(drop=True)
    print(f"[LLM_PRE_ALIGN] very short/empty rows removed: {len(keep_mask) - len(df)}")

    if df.empty:
        raise ValueError("[LLM_PRE_ALIGN] ì „ì²˜ë¦¬ í›„ ë‚¨ì€ êµ¬ê°„ì´ ì—†ìŠµë‹ˆë‹¤.")

    # ====== 2ë‹¨ê³„: ê°™ì€ í™”ìì˜ ì§§ì€ êµ¬ê°„ merge ======
    if merge_same_role:
        merged_rows = []
        rows = list(df.to_dict(orient="records"))

        for r in rows:
            if not merged_rows:
                merged_rows.append(r)
                continue

            prev = merged_rows[-1]
            role_prev = str(prev[role_col]).strip().lower()
            role_cur = str(r[role_col]).strip().lower()

            same_role = (role_prev == role_cur) and role_prev != ""

            gap = float(r[start_col]) - float(prev[end_col])
            prev_dur = float(prev[end_col]) - float(prev[start_col])
            cur_dur = float(r[end_col]) - float(r[start_col])

            should_merge = (
                same_role
                and gap >= 0.0
                and gap <= merge_gap_thresh_sec
                and (prev_dur <= merge_short_thresh_sec or cur_dur <= merge_short_thresh_sec)
            )

            if should_merge:
                # ì‹œê°„ í•©ì¹˜ê¸°
                prev[end_col] = max(float(prev[end_col]), float(r[end_col]))
                prev["orig_end_sec"] = max(
                    float(prev.get("orig_end_sec", prev[end_col])),
                    float(r.get("orig_end_sec", r[end_col])),
                )

                # í…ìŠ¤íŠ¸ í•©ì¹˜ê¸° (orig_text / llm_text / text ëª¨ë‘ ì‹œë„)
                for col in ["orig_text", "llm_text", "text"]:
                    if col in r:
                        prev_val = str(prev.get(col, "") or "").strip()
                        cur_val = str(r.get(col, "") or "").strip()
                        if prev_val and cur_val:
                            prev[col] = (prev_val + " " + cur_val).strip()
                        elif cur_val:
                            prev[col] = cur_val
            else:
                merged_rows.append(r)

        df = pd.DataFrame(merged_rows)
        df = df.sort_values(start_col).reset_index(drop=True)
        print(f"[LLM_PRE_ALIGN] merged rows count: {len(keep_mask)} -> {len(df)}")

    # ====== 2.5ë‹¨ê³„: í•´ì„¤ ìš°ì„  ì „ëµ (ê²¹ì¹˜ëŠ” ìºìŠ¤í„° drop) ======
    if analyst_priority_min_overlap_sec is not None:
        df = _apply_analyst_priority_pre(
            df,
            start_col=start_col,
            end_col=end_col,
            role_col=role_col,
            caster_roles=caster_roles,
            analyst_roles=analyst_roles,
            min_overlap_sec=analyst_priority_min_overlap_sec,
        )

    # ====== 3ë‹¨ê³„: ì—­í• /í…ìŠ¤íŠ¸ ê¸°ë°˜ìœ¼ë¡œ ìŠ¬ë¡¯ ê¸¸ì´ ì¬ê³„ì‚° (TTS ì´ì „ align) ======
    new_starts: list[float] = []
    new_ends: list[float] = []

    prev_end = float(df[start_col].min()) - min_gap_sec  # ì´ì „ ë°œí™” ë ì‹œê°

    for i, row in enumerate(df.itertuples(index=False)):
        role_raw = str(getattr(row, role_col, "")).strip()
        role = role_raw.lower()
    
        orig_start = float(getattr(row, start_col))
        orig_end = float(getattr(row, end_col))
        orig_dur = max(orig_end - orig_start, 0.01)
    
        # 3-1) í…ìŠ¤íŠ¸ ê¸¸ì´ ê¸°ë°˜ duration ì¶”ì •
        pred_dur = _estimate_slot_duration_from_text(
            row,
            role_col=role_col,
            caster_roles=caster_roles,
            analyst_roles=analyst_roles,
            caster_chars_per_sec=caster_chars_per_sec,
            analyst_chars_per_sec=analyst_chars_per_sec,
            dur_margin_ratio=dur_margin_ratio,
        )
    
        # 3-2) extra_ratio ê¸°ë°˜ duration
        if role in caster_roles:
            extra_ratio = caster_extra_ratio
        elif role in analyst_roles:
            extra_ratio = analyst_extra_ratio
        else:
            extra_ratio = 0.0
    
        dur_from_ratio = orig_dur * (1.0 + extra_ratio)
    
        # 3-3) ìµœì¢…ì ìœ¼ë¡œ ì“°ê³  ì‹¶ì€ "ì´ ì¤„ì€ ìµœì†Œ ì´ ì •ë„ëŠ” ì¤˜ì•¼ í•œë‹¤" ê¸¸ì´
        desired_dur = max(orig_dur, pred_dur, dur_from_ratio)
    
        # ğŸ”¥ ì „ì—­ ìŠ¤ì¼€ì¼ ì ìš© (ì „ì²´ì ìœ¼ë¡œ ìŠ¬ë¡¯ ë„“íˆê¸°)
        desired_dur *= global_slot_scale
    
        # í•´ì„¤ì€ ë„ˆë¬´ ê³¼ë„í•˜ê²Œ ì•ˆ ë‚˜ê°€ê²Œ ìƒí•œ
        if role in analyst_roles and max_analyst_expand_sec is not None:
            desired_dur = min(desired_dur, orig_dur + max_analyst_expand_sec)
    
        # ğŸ”¥ startëŠ” "ì ˆëŒ€" ê±´ë“œë¦¬ì§€ ì•Šê³ , ì›ë˜ STT startë¥¼ ê·¸ëŒ€ë¡œ ì‚¬ìš©
        start_aligned = orig_start
    
        # desired_durë§Œí¼ ì˜¤ë¥¸ìª½ìœ¼ë¡œ endë¥¼ ëŠ˜ë¦°ë‹¤
        end_aligned = start_aligned + desired_dur
    
        # ë§Œì•½ ì´ìƒí•˜ê²Œ ë„ˆë¬´ ì§§ì•„ì§€ë©´ ìµœì†Œ ê¸¸ì´ ë³´ì¥
        if end_aligned <= start_aligned + 0.02:
            end_aligned = start_aligned + max(0.02, orig_dur * 0.3)
    
        new_starts.append(start_aligned)
        new_ends.append(end_aligned)
    
        # prev_endëŠ” ì´ì œ "ì°¸ê³ ìš©"ìœ¼ë¡œë§Œ ì—…ë°ì´íŠ¸ (ë‹¤ìŒ ì¤„ startì—ëŠ” ì‚¬ìš© ì•ˆ í•¨)
        prev_end = end_aligned
    
        print(
            f"[LLM_PRE_ALIGN] role={role_raw:8s} "
            f"orig=({orig_start:.3f}~{orig_end:.3f}, dur={orig_dur:.3f}) "
            f"pred_dur={pred_dur:.3f} "
            f"-> aligned=({start_aligned:.3f}~{end_aligned:.3f}, "
            f"dur={end_aligned-start_aligned:.3f})"
        )

    df[start_col] = new_starts
    df[end_col] = new_ends

    # ====== 4ë‹¨ê³„: CSV ì €ì¥ (orig_* ì»¬ëŸ¼ì€ ì œê±°) ======
    if out_csv_path is None:
        # ì˜ˆ: clip.tts_phrases.llm_kanana.csv -> clip.tts_phrases.llm_kanana.pre_aligned.csv
        stem = llm_csv_path.stem
        out_csv_path = llm_csv_path.with_name(stem + ".pre_aligned.csv")

    out_csv_path = Path(out_csv_path)
    out_csv_path.parent.mkdir(parents=True, exist_ok=True)

    # ìµœì¢… ì¶œë ¥ì—ì„œëŠ” orig_start_sec, orig_end_sec ë¥¼ ì œê±°
    df_out = df.copy()
    df_out = df_out.drop(columns=["orig_start_sec", "orig_end_sec"], errors="ignore")

    df_out.to_csv(out_csv_path, index=False, encoding="utf-8-sig")
    print("[LLM_PRE_ALIGN] saved preprocessed+aligned CSV:", out_csv_path)

    return out_csv_path
