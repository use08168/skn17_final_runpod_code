# src/pipeline.py

from __future__ import annotations

import subprocess
from dataclasses import dataclass, field
from pathlib import Path
from typing import Dict, Optional

import pandas as pd

from . import PROJECT_ROOT, DATA_DIR, FAISS_DIR
from .stt_clova import run_stt_to_csv
from .rag_faiss import load_full_match_log
from .llm_kanana import KananaConfig, KananaCommentaryModel
from .tts_fishspeech import synthesize_with_openaudio

# ë””ë ‰í† ë¦¬ë“¤
INPUT_DIR = DATA_DIR / "input_videos"
STT_SEG_DIR = DATA_DIR / "stt_segments"
LLM_OUT_DIR = DATA_DIR / "llm_outputs"
TTS_DIR = DATA_DIR / "tts_audio"
FINAL_DIR = DATA_DIR / "final_videos"

for d in [INPUT_DIR, STT_SEG_DIR, LLM_OUT_DIR, TTS_DIR, FINAL_DIR]:
    d.mkdir(parents=True, exist_ok=True)


@dataclass
class PipelineConfig:
    # ==== STT (CLOVA) ====
    clova_invoke_url: str       # ğŸ”¥ ì—¬ê¸°ì— invoke URL í•˜ë“œì½”ë”© or í˜¸ì¶œ ì‹œ ì „ë‹¬
    clova_secret_key: str       # ğŸ”¥ ì—¬ê¸°ì— CLOVA ì‹œí¬ë¦¿ í‚¤

    stt_keyword_xlsx: str       # í‚¤ì›Œë“œ ì—‘ì…€ ê²½ë¡œ (ì˜ˆ: "/workspace/baseball_pipeline/stt.xlsx")

    # ==== RAG (FAISS + OpenAI Embeddings) ====
    faiss_db_path: Optional[str] = None  # Noneì´ë©´ /faiss_index
    openai_api_key: Optional[str] = None # ğŸ”¥ í•„ìš”í•˜ë©´ OpenAI API í‚¤

    # ==== LLM (Kanana) ====
    hf_token: Optional[str] = None       # ğŸ”¥ Hugging Face í† í°
    match_title: str = "2025 í•œêµ­ì‹œë¦¬ì¦ˆ 1ì°¨ì „"

    # ==== TTS (Fish-speech / OpenAudio) ====
    fish_checkpoint_dir: Optional[str] = None  # Noneì´ë©´ PROJECT_ROOT/fish-speech/checkpoints/openaudio-s1-mini
    caster_prompt_wav: str = str(PROJECT_ROOT / "fish-speech" / "references" / "caster_prompt.wav")
    commentator_prompt_wav: str = str(PROJECT_ROOT / "fish-speech" / "references" / "commentator_prompt.wav")

    # ==== í™”ì ë¼ë²¨ â†’ ì—­í•  ë§¤í•‘ ====
    # ì˜ˆ: A=ìºìŠ¤í„°, B=í•´ì„¤
    speaker_role_map: Dict[str, str] = field(default_factory=lambda: {"A": "caster", "B": "commentator"})

    def get_faiss_db_path(self) -> str:
        if self.faiss_db_path is not None:
            return self.faiss_db_path
        return str(FAISS_DIR)

    def get_fish_checkpoint_dir(self) -> Path:
        if self.fish_checkpoint_dir is not None:
            return Path(self.fish_checkpoint_dir)
        return PROJECT_ROOT / "fish-speech" / "checkpoints" / "openaudio-s1-mini"


def replace_audio_with_ffmpeg(
    input_mp4: Path,
    new_audio_wav: Path,
    output_mp4: Path,
) -> Path:
    """
    ê¸°ì¡´ ì˜ìƒì˜ 'ì˜ìƒ íŠ¸ë™'ì€ ê·¸ëŒ€ë¡œ ë‘ê³ , ì˜¤ë””ì˜¤ë¥¼ new_audio_wavë¡œ êµì²´.
    """
    cmd = [
        "ffmpeg",
        "-y",
        "-i",
        str(input_mp4),
        "-i",
        str(new_audio_wav),
        "-c:v",
        "copy",
        "-map",
        "0:v:0",
        "-map",
        "1:a:0",
        "-shortest",
        str(output_mp4),
    ]
    print("[FFMPEG] ëª…ë ¹:", " ".join(cmd))
    proc = subprocess.run(cmd)
    if proc.returncode != 0:
        raise RuntimeError(f"ffmpeg ì‹¤íŒ¨ (return code={proc.returncode})")
    print(f"[FFMPEG] ìƒˆ ì˜ìƒ ìƒì„±: {output_mp4}")
    return output_mp4


def run_full_pipeline(
    video_filename: str,   # data/input_videos ë°‘ì— ìˆëŠ” íŒŒì¼ ì´ë¦„ (ì˜ˆ: "my_clip.mp4")
    cfg: PipelineConfig,
) -> Dict[str, Path]:
    """
    1) MP4 â†’ CLOVA STT CSV (data/stt_segments)
    2) FAISSì—ì„œ ê²½ê¸° ë¡œê·¸ ë¡œë“œ
    3) í•´ì„¤ ë©˜íŠ¸ë¥¼ ë°•ì°¬í˜¸ ìŠ¤íƒ€ì¼ë¡œ ë³€í™˜
    4) ìºìŠ¤í„°+í•´ì„¤ í†µí•© ìŠ¤í¬ë¦½íŠ¸ â†’ TTS
    5) ê¸°ì¡´ mp4ì— ìƒˆ ì˜¤ë””ì˜¤ ì…í˜€ì„œ ìµœì¢… mp4 ìƒì„±

    âš  í˜„ì¬ ë²„ì „ì€ "ì „ì²´ ìŠ¤í¬ë¦½íŠ¸ë¥¼ í•œ ë²ˆì— TTS" í•˜ëŠ” ë‹¨ìˆœ ë²„ì „.
      ë‚˜ì¤‘ì— segment ë‹¨ìœ„ë¡œ ì˜ë¼ì„œ íƒ€ì„ìŠ¤íƒ¬í”„ ê¸°ë°˜ìœ¼ë¡œ í•©ì„±í•˜ëŠ” ë²„ì „ìœ¼ë¡œ í™•ì¥ ê°€ëŠ¥.
    """
    video_path = INPUT_DIR / video_filename
    if not video_path.exists():
        raise FileNotFoundError(f"ì…ë ¥ ì˜ìƒì´ ì—†ìŠµë‹ˆë‹¤: {video_path}")

    # ---------- 1) STT ----------
    stt_csv = run_stt_to_csv(
        audio_path=video_path,
        xlsx_keywords_path=cfg.stt_keyword_xlsx,
        invoke_url=cfg.clova_invoke_url,
        secret_key=cfg.clova_secret_key,
        speaker_count_min=2,
        speaker_count_max=2,
        save_raw_json=True,
    )

    df = pd.read_csv(stt_csv)
    print(f"[PIPE] STT segments: {len(df)} rows")

    # ---------- 2) ê²½ê¸° ë¡œê·¸ (RAG) ----------
    match_log = load_full_match_log(
        target_match=cfg.match_title,
        db_path=cfg.get_faiss_db_path(),
        openai_api_key=cfg.openai_api_key,
    ) or ""
    print(f"[PIPE] ê²½ê¸° ë¡œê·¸ ê¸¸ì´: {len(match_log)} chars")

    # ---------- 3) LLM: í•´ì„¤ ë©˜íŠ¸ ë³€í™˜ ----------
    llm_cfg = KananaConfig(
        hf_token=cfg.hf_token,
        max_new_tokens=256,
    )
    llm = KananaCommentaryModel(llm_cfg)

    # í™”ì ë¼ë²¨ â†’ ì—­í• 
    def map_role(row):
        label = str(row.get("speaker_label") or "").strip()
        return cfg.speaker_role_map.get(label, "unknown")

    df["role"] = df.apply(map_role, axis=1)

    # commentator ë³€í™˜ ê²°ê³¼ë¥¼ ìˆœì„œëŒ€ë¡œ ë‹´ì•„ ë‘ê¸°
    park_text_list = []

    for _, row in df.iterrows():
        text = str(row.get("text") or "").strip()
        if not text:
            park_text_list.append("")  # ìë¦¬ë§Œ ë§ì¶”ê¸°
            continue

        role = row["role"]
        if role == "commentator":
            park_text = llm.generate_park_style(
                match_log=match_log,
                original_text=text,
            )
            park_text_list.append(park_text)
        else:
            park_text_list.append("")

    # ---------- 3-2) í†µí•© ìŠ¤í¬ë¦½íŠ¸ ë§Œë“¤ê¸° ----------
    merged_script_lines = []
    park_idx = 0
    for _, row in df.iterrows():
        text = str(row.get("text") or "").strip()
        if not text:
            continue
        role = row["role"]

        if role == "caster":
            merged_script_lines.append(f"[ìºìŠ¤í„°] {text}")
        elif role == "commentator":
            park_text = park_text_list[park_idx]
            park_idx += 1
            if not park_text:
                park_text = text
            merged_script_lines.append(f"[ë°•ì°¬í˜¸] {park_text}")
        else:
            # ì—­í•  ëª¨ë¥¼ ë•ŒëŠ” ê·¸ëƒ¥ ì›ë³¸
            merged_script_lines.append(text)

    merged_script = "\n".join(merged_script_lines)
    script_path = LLM_OUT_DIR / f"{video_path.stem}_script.txt"
    script_path.write_text(merged_script, encoding="utf-8")
    print(f"[PIPE] í†µí•© ìŠ¤í¬ë¦½íŠ¸ ì €ì¥: {script_path}")

    # ---------- 4) TTS ----------
    tts_out_wav = TTS_DIR / f"{video_path.stem}_tts.wav"
    _ = synthesize_with_openaudio(
        text=merged_script,
        speaker="commentator",  # ì „ì²´ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì¼ë‹¨ ë°•ì°¬í˜¸ ëª©ì†Œë¦¬ë¡œ
        output_wav=tts_out_wav,
        prompt_wav_caster=Path(cfg.caster_prompt_wav),
        prompt_wav_commentator=Path(cfg.commentator_prompt_wav),
        checkpoint_dir=cfg.get_fish_checkpoint_dir(),
        prompt_text="ì•¼êµ¬ ì¤‘ê³„ ì°¸ê³  ìŒì„±ì— í•´ë‹¹í•˜ëŠ” í…ìŠ¤íŠ¸",
    )

    # ---------- 5) ffmpegë¡œ ìƒˆë¡œìš´ mp4 ë§Œë“¤ê¸° ----------
    final_mp4 = FINAL_DIR / f"{video_path.stem}_park_version.mp4"
    _ = replace_audio_with_ffmpeg(
        input_mp4=video_path,
        new_audio_wav=tts_out_wav,
        output_mp4=final_mp4,
    )

    print("[PIPE] ì „ì²´ íŒŒì´í”„ë¼ì¸ ì™„ë£Œ.")
    return {
        "stt_csv": Path(stt_csv),
        "script_txt": script_path,
        "tts_wav": tts_out_wav,
        "final_mp4": final_mp4,
    }
